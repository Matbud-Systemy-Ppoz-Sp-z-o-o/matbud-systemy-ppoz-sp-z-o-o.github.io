{"version":3,"file":"static/chunks/8679.e956dfea908f9ba7.js","mappings":"0HAYA,SAeO,SAAS,EAAQ,KACxB,KADwB,CACxB,KAQA,WANA,qCACA,kBAGA,+CAGA,CAcA,sBAsDA,EArDA,GAsDA,CADA,EArDA,IAsDA,mBAtDA,CACA,eACA,oCAGA,uBACA,aAGA,kBACA,OAAa,EAAG,eAEhB,QAEA,iBACW,EAAG,OAGd,EACA,CAcA,SAAS,EAAG,OAEZ,SACA,KAEA,mBACA,iBAGA,iBACA,oCE3FA,kCAMO,cACP,cAA6C,CAC7C,eACA,0BAQA,CAGA,QAA2D,SAA3D,cACA,aASA,QACA,6DCvBO,OACP,WACA,SAQA,gBACA,OAgBA,YACA,MAAW,QAAa,IAAS,OAAY,0BAC7C,EAgBA,cACA,iBAA4B,QAAkB,aAC9C,CACA,CA7CA,2RCGO,OACP,iBACA,WAUA,cACA,IAEA,EAEA,EAEA,EAEA,EAEA,EAEA,EAEA,EAEA,EAhBA,KAsBA,mBAEA,yEAIA,KAHA,IAGA,KAEA,wEAEA,mFAKA,wKACA,SAIA,2FACA,OACA,gBAEA,GACA,kBAEA,QACA,OACA,GACA,6CACA,QACA,KACA,eAEA,EACA,GACA,6CACA,OACA,iBACa,CACb,KACA,EACA,GACA,qCACA,OACA,eACa,CACb,KACA,iBAEA,EACA,GACA,6BACA,OACA,UACA,CAAa,CACb,KACA,SAEA,EACA,aACA,YAEA,eACA,UAEA,KAGA,yCACA,GAAyB,OAAI,8CAI7B,EAAuB,OAAI,6DAK3B,EAAuB,OAAI,GAAa,OAAU,wDAGlD,EAAuB,OAAI,2DAG3B,yCACA,IACA,EAAyB,OAAI,8CAE7B,IAEU,OAAM,gBAChB,iBACA,KACA,CACA,CAMA,IADA,KACA,cACA,oCACA,sBAGA,QACA,EA5IA,SAmJA,cACA,IAKA,EALA,+CACA,gBACA,EAAiB,OAAiB,IAIlC,OAYA,YAGA,OAFA,IACA,6BACA,SAaA,KACA,SAEA,OADA,aACA,EAEA,kCAGA,EAAkB,OAAiB,IAInC,8BACA,8BAGA,OAFA,gCACA,iCACA,IACA,EA9BA,EACA,CA8BA,CAvMA,EAsNA,gBACA,YACA,YACA,iBACA,eCrOO,OACP,gBACA,SAQA,gBACA,QACA,OAcA,YAMA,OALA,oBACA,0BACA,aACA,yBACA,4BACA,CACA,EAcA,oBACQ,QAAU,KAClB,aACA,GAEA,OACA,KAEA,IACA,CAcA,qBAEA,wBAAqD,QAAiB,KAEtE,IAkBA,qBACA,QACA,aACA,IACA,GAIA,yBAAsD,QAAiB,cACvE,aACA,IAEA,IACA,KACA,EA/BA,IAEA,IACA,CAwCA,qBACA,QACA,2BACA,0BACA,aACA,yBACA,mBACA,GAIA,0BAAuD,QAAY,IACnE,MAEA,aACA,EACA,CAYA,qBACA,QACA,aACA,GAEQ,QAAU,KAClB,aACA,GAEA,IACA,CAYA,cACA,MAAW,QAAiB,IAa5B,qBACA,QACA,aACA,IACA,GAEA,QAEA,gDACA,0BACA,aACA,yBACA,mBACA,GAEA,SAeA,KAEA,YAAwB,QAAiB,cACzC,iBAEA,OADA,aACA,CACA,CACA,WACA,EAvBA,EACA,EA7B4B,OAC5B,CAmDA,CA1NA,4BCDO,OACP,cACA,SAgFA,gBACA,WACA,OAeA,kBACA,CAAQ,OAAa,IAGR,OAAY,yFAEzB,IACA,EAeA,cACA,0BACA,CACA,CAzHA,CAAG,CACH,KA2HA,YACA,oBACA,EA5HA,kBACA,SAQA,gBACA,WACA,OAYA,YACA,WACA,uBAWA,OAVA,SACA,sBACA,aACA,CAAS,EACT,WAEA,4BACA,4BACA,aACA,2BACA,CACA,CACA,WACA,EAYA,oBACA,CAAQ,OAAa,KACrB,sCACA,aACA,qCACA,2BACA,IAEA,2BACA,KACA,CACA,CA5DA,ECTO,GACP,uBACA,SAQA,gBACA,OAYA,YAKA,OAJA,2BACA,wBACA,aACA,uBACA,CACA,EAYA,oBAEA,CAAQ,OAAgB,KACxB,gCACA,aACA,+BACA,0BACA,GAEA,IACA,CACA,CAjDA,iBCDO,OACP,0BACA,SAQA,gBACA,IAGA,EAEA,EALA,OACA,IAKA,OAgBA,YAKA,OAJA,8BACA,oCACA,aACA,mCACA,CACA,EAiBA,qBACA,QACA,2CACA,aACA,0CACA,IAEA,mCACA,KACA,EAAW,IAAiB,CAC5B,KACA,CAcA,qBACA,iBACA,+CACA,aACA,8CACA,mCACA,IACA,EAAa,IAAa,CAC1B,IAEA,mCACA,IACA,EAAW,IAAU,CACrB,KACA,CAmBA,cACA,cACA,+CACA,IAAmB,IAAiB,EAAK,OAA6B,uBAMtE,oCACA,aACA,mCACA,6BACA,GATA,IAUA,QACA,aACA,aACA,GAEA,IACA,CACA,CApIA,ECHA,GACA,WACA,SAiaA,gBACA,WACA,OAOA,mBACA,SACA,MAEA,sBACA,aACA,qBACA,EACA,EAOA,cACA,4CACA,CACA,CA3bA,EAGO,GACP,YACA,kBACA,SAQA,gBACA,IASA,EATA,OAEA,GACA,WACA,SAiSA,gBACA,QACA,OAOA,YAIA,OAHA,sBACA,aACA,qBACA,CACA,EAcA,cAKA,OADA,2BACa,QAAa,IAAS,OAAY,6FAC/C,CAcA,qBACA,OACA,mCACA,SAiBA,YACA,OACA,IACA,aACA,GAEA,MACA,kCACe,QAAa,IAAS,OAAY,4BAEjD,IACA,EA5BA,IAEA,IACA,CAuCA,qBACA,UAA2B,QAAkB,KAC7C,0BACA,MAEA,IACA,CACA,CApYA,EACA,IACA,IAGA,OAcA,gBAiBA,EAfA,EAgBA,kCAMA,OALA,oEACA,IACA,sBACA,2BACA,mCACA,SAeA,YACA,OACA,IACA,aACA,GAEA,IACA,MAEA,kCACW,QAAa,IAAS,OAAY,2BAC7C,EA1BA,EArBA,EA6DA,qBACA,UAAyB,QAAkB,KAC3C,0BACA,qCAEA,+BACA,uBACA,oBACA,CAAK,EACL,SAeA,YACA,UAAyB,QAAkB,KAC3C,sBACA,8BACA,MAEQ,QAAa,KACrB,sBACA,8BACa,OAAY,uBAEzB,cACA,MAEA,aACA,EACA,EA/BA,GACA,CA4CA,qBACA,UAAyB,QAAkB,IAC3C,MAEA,+BACA,uBACA,oBACA,CAAK,EACL,SAeA,YACA,UAAyB,QAAkB,KAC3C,sBACA,8BACA,MAEA,cACA,MAEA,aACA,EACA,EA1BA,GACA,CAwCA,cACA,0BACA,CAcA,cAIA,OAHA,sBACA,aACA,qBACA,CACA,CAcA,cACA,YAAgC,QAAa,IAAS,OAAY,8BAClE,CAcA,qBACA,UAAyB,QAAkB,IAC3C,mBAEA,yBACA,SAeA,YACA,UAAyB,QAAkB,KAC3C,wBACA,OAEA,aACA,EACA,EAtBA,GACA,CAmCA,cAEA,OADA,qBACA,IACA,CA4GA,CAlZA,ECXO,GACP,oBACA,SAcA,gBACA,WACA,OAgBA,YAMA,OAHA,wBAGW,OAAY,uBACvB,EAYA,cACA,kCACA,oFAaA,YACA,SACA,KAEQ,QAAkB,IAC1B,qBAEA,yBACA,SAaA,YACA,UAAyB,QAAkB,KAC3C,wBACA,OAEA,aACA,EACA,EApBA,GACA,EAtBA,OACA,CA2CA,cAKA,OAJA,uBAIA,IACA,CACA,CAvGA,EAGA,GACA,WACA,SAyGA,gBACA,WACA,SAaA,qBAGA,4BACA,KAEQ,QAAkB,KAC1B,sBACA,aACA,qBACA,GASW,OAAY,uBACvB,CAYA,cACA,kCACA,gFAAmH,QAAkB,aACrI,CACA,CA3JA,ECPO,GACP,gBACA,SA2DA,YAEA,4EACA,EA7DA,QAMA,YACA,IAGA,EAEA,EALA,aACA,IAOA,qBAPA,EAOA,yFAIA,KAHA,IAGA,OACA,kCAEA,+BACA,+BACA,KACA,KACA,KACA,CACA,CAMA,IAFA,MACA,IACA,QACA,WACA,oCACA,MAEM,uCACN,4BACA,UACA,0BACA,oBACA,SACA,OAEA,UAGA,QACA,EAlDA,SAmEA,gBAEA,IAEA,EAEA,EAJA,IAKA,OAcA,YAGA,OAFA,oBACA,4BACA,SAaA,YACA,QACA,aACA,IACA,IAEA,2BACA,KACA,EArBA,EACA,EAgCA,qBAEA,SACA,KAMA,QACA,iBACA,aACA,gBACA,GAIA,QACA,8BACA,IA4CA,qBAEA,QACA,aACA,IACA,GAIA,OACA,2BACA,mBACA,OAIA,sBACA,KACA,EA7DA,IAEQ,QAAkB,KAC1B,sBACA,aACA,qBACA,IAIA,wBACA,KACA,CAYA,qBACA,0BAAuD,QAAkB,KACzE,uBACA,OAEA,aACA,EACA,CA+BA,CA7MA,iBCDO,OACP,QAgBA,YAEA,MADE,OAAW,IACb,CACA,EAlBA,SAyBA,cAEA,MACA,OAYA,YAKA,OAJA,mBACA,0BACA,qBACA,CAAK,EACL,IACA,EAYA,qBACA,SACA,KAKQ,QAAkB,IAC1B,mBAIA,aACA,EACA,CAOA,cAGA,OAFA,uBACA,kBACA,IACA,CAOA,cAQA,OAPA,aACA,uBACA,+BACA,sBACA,UACA,CAAK,EACL,SACA,CACA,CACA,CAnGA,EAGA,GACA,WACA,SAqGA,gBACA,WACA,OAOA,YAKA,OAJA,uBACA,sBACA,aACA,qBACW,OAAY,kBACvB,EAOA,cACA,aAAyB,QAAkB,IAC3C,YAKA,wCACA,gIACA,KAEA,4CACA,CACA,CAvIA,6DCVO,OACP,kBACA,SAcA,gBACA,IAEA,EAFA,OAGA,OAYA,gBAkBA,EAbA,OADA,sBAcA,EAbA,EAgBW,GAAY,YAEvB,uEAjBA,EA8BA,oBAEA,CADA,EAAiB,OAAmB,+DACpC,SACA,4BACA,aACA,2BACA,GAEA,IACA,CAYA,cAEA,MAAW,QAAyB,IAAS,OAAiB,aAC9D,CAYA,cACA,MAAW,OAAkB,KAE7B,0JACA,CAYA,cACA,0BACA,CAcA,cACA,MAAW,QAAa,IAAS,OAAY,0BAC7C,CAcA,qBACA,UAAyB,QAAkB,KAC3C,qBAKA,yBAKA,MAEA,IACA,CACA,CArKA,EAGA,GACA,WACA,SAuKA,gBACA,OAcA,YACA,MAAW,QAAyB,IAAS,OAAiB,aAC9D,EAaA,cACA,MAAW,OAAY,4EACvB,CAYA,cACA,MAAW,QAAa,IAAS,OAAY,0BAC7C,CAYA,cACA,iBAA4B,QAAkB,aAC9C,CACA,CAnOA,ECfO,GACP,uBACA,SAQA,gBACA,OAaA,YAGA,OAFA,2BACA,aACA,CACA,EAaA,oBACA,CAAQ,OAAkB,KAC1B,0BACA,MAEA,IACA,CACA,CA7CA,ECCO,GACP,kBACA,QAKA,cACA,IAGA,EAEA,EALA,aACA,IAgCA,MAzBA,iBAPA,EAOA,UACA,OAIA,oCACA,OAEA,sFACA,iBAEA,MACA,GACA,sBACA,oBACA,iBAEA,GACA,iBACA,oBACA,gBACA,kBACA,EACI,OAAM,qEAEV,CACA,EAvCA,SA8CA,gBACA,QACA,OAYA,gBAgBA,EAbA,OADA,sBAcA,EAbA,EAcA,8BACA,SAaA,YACA,eACA,aACA,GAIA,UAAyB,QAAyB,KAClD,6BACA,SAeA,YACA,QACA,8BACA,SA+BA,YACA,QACA,aACA,IAEA,6BACA,KACA,EAtCA,IAEA,UAAyB,QAAkB,KAC3C,qBAIA,MAEQ,QAAa,IACR,OAAY,uBAKzB,0BAmCA,qBACA,kBAAwC,QAAyB,KACjE,yBACA,OAEA,aACA,EACA,EAzCA,GACA,EAnCA,IAEA,IACA,EAzBA,EAdA,CAgHA,CA/KA","sources":["webpack://_N_E/./node_modules/mdast-util-to-string/lib/index.js","webpack://_N_E/./node_modules/mdast-util-to-string/index.js","webpack://_N_E/./node_modules/decode-named-character-reference/index.dom.js","webpack://_N_E/./node_modules/micromark-core-commonmark/lib/blank-line.js","webpack://_N_E/./node_modules/micromark-core-commonmark/lib/attention.js","webpack://_N_E/./node_modules/micromark-core-commonmark/lib/autolink.js","webpack://_N_E/./node_modules/micromark-core-commonmark/lib/block-quote.js","webpack://_N_E/./node_modules/micromark-core-commonmark/lib/character-escape.js","webpack://_N_E/./node_modules/micromark-core-commonmark/lib/character-reference.js","webpack://_N_E/./node_modules/micromark-core-commonmark/lib/code-fenced.js","webpack://_N_E/./node_modules/micromark-core-commonmark/lib/code-indented.js","webpack://_N_E/./node_modules/micromark-core-commonmark/lib/code-text.js","webpack://_N_E/./node_modules/micromark-core-commonmark/lib/content.js","webpack://_N_E/./node_modules/micromark-core-commonmark/lib/definition.js","webpack://_N_E/./node_modules/micromark-core-commonmark/lib/hard-break-escape.js","webpack://_N_E/./node_modules/micromark-core-commonmark/lib/heading-atx.js","webpack://_N_E/./node_modules/micromark-core-commonmark/index.js"],"sourcesContent":["/**\n * @typedef {import('mdast').Nodes} Nodes\n *\n * @typedef Options\n *   Configuration (optional).\n * @property {boolean | null | undefined} [includeImageAlt=true]\n *   Whether to use `alt` for `image`s (default: `true`).\n * @property {boolean | null | undefined} [includeHtml=true]\n *   Whether to use `value` of HTML (default: `true`).\n */\n\n/** @type {Options} */\nconst emptyOptions = {}\n\n/**\n * Get the text content of a node or list of nodes.\n *\n * Prefers the node‚Äôs plain-text fields, otherwise serializes its children,\n * and if the given value is an array, serialize the nodes in it.\n *\n * @param {unknown} [value]\n *   Thing to serialize, typically `Node`.\n * @param {Options | null | undefined} [options]\n *   Configuration (optional).\n * @returns {string}\n *   Serialized `value`.\n */\nexport function toString(value, options) {\n  const settings = options || emptyOptions\n  const includeImageAlt =\n    typeof settings.includeImageAlt === 'boolean'\n      ? settings.includeImageAlt\n      : true\n  const includeHtml =\n    typeof settings.includeHtml === 'boolean' ? settings.includeHtml : true\n\n  return one(value, includeImageAlt, includeHtml)\n}\n\n/**\n * One node or several nodes.\n *\n * @param {unknown} value\n *   Thing to serialize.\n * @param {boolean} includeImageAlt\n *   Include image `alt`s.\n * @param {boolean} includeHtml\n *   Include HTML.\n * @returns {string}\n *   Serialized node.\n */\nfunction one(value, includeImageAlt, includeHtml) {\n  if (node(value)) {\n    if ('value' in value) {\n      return value.type === 'html' && !includeHtml ? '' : value.value\n    }\n\n    if (includeImageAlt && 'alt' in value && value.alt) {\n      return value.alt\n    }\n\n    if ('children' in value) {\n      return all(value.children, includeImageAlt, includeHtml)\n    }\n  }\n\n  if (Array.isArray(value)) {\n    return all(value, includeImageAlt, includeHtml)\n  }\n\n  return ''\n}\n\n/**\n * Serialize a list of nodes.\n *\n * @param {Array<unknown>} values\n *   Thing to serialize.\n * @param {boolean} includeImageAlt\n *   Include image `alt`s.\n * @param {boolean} includeHtml\n *   Include HTML.\n * @returns {string}\n *   Serialized nodes.\n */\nfunction all(values, includeImageAlt, includeHtml) {\n  /** @type {Array<string>} */\n  const result = []\n  let index = -1\n\n  while (++index < values.length) {\n    result[index] = one(values[index], includeImageAlt, includeHtml)\n  }\n\n  return result.join('')\n}\n\n/**\n * Check if `value` looks like a node.\n *\n * @param {unknown} value\n *   Thing.\n * @returns {value is Nodes}\n *   Whether `value` is a node.\n */\nfunction node(value) {\n  return Boolean(value && typeof value === 'object')\n}\n","/**\n * @typedef {import('./lib/index.js').Options} Options\n */\n\nexport {toString} from './lib/index.js'\n","/// <reference lib=\"dom\" />\n\n/* global document */\n\nconst element = document.createElement('i')\n\n/**\n * @param {string} value\n * @returns {string | false}\n */\nexport function decodeNamedCharacterReference(value) {\n  const characterReference = '&' + value + ';'\n  element.innerHTML = characterReference\n  const character = element.textContent\n\n  // Some named character references do not require the closing semicolon\n  // (`&not`, for instance), which leads to situations where parsing the assumed\n  // named reference of `&notit;` will result in the string `¬¨it;`.\n  // When we encounter a trailing semicolon after parsing, and the character\n  // reference to decode was not a semicolon (`&semi;`), we can assume that the\n  // matching was not complete.\n  if (\n    // @ts-expect-error: TypeScript is wrong that `textContent` on elements can\n    // yield `null`.\n    character.charCodeAt(character.length - 1) === 59 /* `;` */ &&\n    value !== 'semi'\n  ) {\n    return false\n  }\n\n  // If the decoded string is equal to the input, the character reference was\n  // not valid.\n  // @ts-expect-error: TypeScript is wrong that `textContent` on elements can\n  // yield `null`.\n  return character === characterReference ? false : character\n}\n","/**\n * @import {\n *   Construct,\n *   State,\n *   TokenizeContext,\n *   Tokenizer\n * } from 'micromark-util-types'\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding, markdownSpace } from 'micromark-util-character';\n/** @type {Construct} */\nexport const blankLine = {\n  partial: true,\n  tokenize: tokenizeBlankLine\n};\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n */\nfunction tokenizeBlankLine(effects, ok, nok) {\n  return start;\n\n  /**\n   * Start of blank line.\n   *\n   * > üëâ **Note**: `‚ê†` represents a space character.\n   *\n   * ```markdown\n   * > | ‚ê†‚ê†‚êä\n   *     ^\n   * > | ‚êä\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    return markdownSpace(code) ? factorySpace(effects, after, \"linePrefix\")(code) : after(code);\n  }\n\n  /**\n   * At eof/eol, after optional whitespace.\n   *\n   * > üëâ **Note**: `‚ê†` represents a space character.\n   *\n   * ```markdown\n   * > | ‚ê†‚ê†‚êä\n   *       ^\n   * > | ‚êä\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function after(code) {\n    return code === null || markdownLineEnding(code) ? ok(code) : nok(code);\n  }\n}","/**\n * @import {\n *   Code,\n *   Construct,\n *   Event,\n *   Point,\n *   Resolver,\n *   State,\n *   TokenizeContext,\n *   Tokenizer,\n *   Token\n * } from 'micromark-util-types'\n */\n\nimport { push, splice } from 'micromark-util-chunked';\nimport { classifyCharacter } from 'micromark-util-classify-character';\nimport { resolveAll } from 'micromark-util-resolve-all';\n/** @type {Construct} */\nexport const attention = {\n  name: 'attention',\n  resolveAll: resolveAllAttention,\n  tokenize: tokenizeAttention\n};\n\n/**\n * Take all events and resolve attention to emphasis or strong.\n *\n * @type {Resolver}\n */\n// eslint-disable-next-line complexity\nfunction resolveAllAttention(events, context) {\n  let index = -1;\n  /** @type {number} */\n  let open;\n  /** @type {Token} */\n  let group;\n  /** @type {Token} */\n  let text;\n  /** @type {Token} */\n  let openingSequence;\n  /** @type {Token} */\n  let closingSequence;\n  /** @type {number} */\n  let use;\n  /** @type {Array<Event>} */\n  let nextEvents;\n  /** @type {number} */\n  let offset;\n\n  // Walk through all events.\n  //\n  // Note: performance of this is fine on an mb of normal markdown, but it‚Äôs\n  // a bottleneck for malicious stuff.\n  while (++index < events.length) {\n    // Find a token that can close.\n    if (events[index][0] === 'enter' && events[index][1].type === 'attentionSequence' && events[index][1]._close) {\n      open = index;\n\n      // Now walk back to find an opener.\n      while (open--) {\n        // Find a token that can open the closer.\n        if (events[open][0] === 'exit' && events[open][1].type === 'attentionSequence' && events[open][1]._open &&\n        // If the markers are the same:\n        context.sliceSerialize(events[open][1]).charCodeAt(0) === context.sliceSerialize(events[index][1]).charCodeAt(0)) {\n          // If the opening can close or the closing can open,\n          // and the close size *is not* a multiple of three,\n          // but the sum of the opening and closing size *is* multiple of three,\n          // then don‚Äôt match.\n          if ((events[open][1]._close || events[index][1]._open) && (events[index][1].end.offset - events[index][1].start.offset) % 3 && !((events[open][1].end.offset - events[open][1].start.offset + events[index][1].end.offset - events[index][1].start.offset) % 3)) {\n            continue;\n          }\n\n          // Number of markers to use from the sequence.\n          use = events[open][1].end.offset - events[open][1].start.offset > 1 && events[index][1].end.offset - events[index][1].start.offset > 1 ? 2 : 1;\n          const start = {\n            ...events[open][1].end\n          };\n          const end = {\n            ...events[index][1].start\n          };\n          movePoint(start, -use);\n          movePoint(end, use);\n          openingSequence = {\n            type: use > 1 ? \"strongSequence\" : \"emphasisSequence\",\n            start,\n            end: {\n              ...events[open][1].end\n            }\n          };\n          closingSequence = {\n            type: use > 1 ? \"strongSequence\" : \"emphasisSequence\",\n            start: {\n              ...events[index][1].start\n            },\n            end\n          };\n          text = {\n            type: use > 1 ? \"strongText\" : \"emphasisText\",\n            start: {\n              ...events[open][1].end\n            },\n            end: {\n              ...events[index][1].start\n            }\n          };\n          group = {\n            type: use > 1 ? \"strong\" : \"emphasis\",\n            start: {\n              ...openingSequence.start\n            },\n            end: {\n              ...closingSequence.end\n            }\n          };\n          events[open][1].end = {\n            ...openingSequence.start\n          };\n          events[index][1].start = {\n            ...closingSequence.end\n          };\n          nextEvents = [];\n\n          // If there are more markers in the opening, add them before.\n          if (events[open][1].end.offset - events[open][1].start.offset) {\n            nextEvents = push(nextEvents, [['enter', events[open][1], context], ['exit', events[open][1], context]]);\n          }\n\n          // Opening.\n          nextEvents = push(nextEvents, [['enter', group, context], ['enter', openingSequence, context], ['exit', openingSequence, context], ['enter', text, context]]);\n\n          // Always populated by defaults.\n\n          // Between.\n          nextEvents = push(nextEvents, resolveAll(context.parser.constructs.insideSpan.null, events.slice(open + 1, index), context));\n\n          // Closing.\n          nextEvents = push(nextEvents, [['exit', text, context], ['enter', closingSequence, context], ['exit', closingSequence, context], ['exit', group, context]]);\n\n          // If there are more markers in the closing, add them after.\n          if (events[index][1].end.offset - events[index][1].start.offset) {\n            offset = 2;\n            nextEvents = push(nextEvents, [['enter', events[index][1], context], ['exit', events[index][1], context]]);\n          } else {\n            offset = 0;\n          }\n          splice(events, open - 1, index - open + 3, nextEvents);\n          index = open + nextEvents.length - offset - 2;\n          break;\n        }\n      }\n    }\n  }\n\n  // Remove remaining sequences.\n  index = -1;\n  while (++index < events.length) {\n    if (events[index][1].type === 'attentionSequence') {\n      events[index][1].type = 'data';\n    }\n  }\n  return events;\n}\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n */\nfunction tokenizeAttention(effects, ok) {\n  const attentionMarkers = this.parser.constructs.attentionMarkers.null;\n  const previous = this.previous;\n  const before = classifyCharacter(previous);\n\n  /** @type {NonNullable<Code>} */\n  let marker;\n  return start;\n\n  /**\n   * Before a sequence.\n   *\n   * ```markdown\n   * > | **\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    marker = code;\n    effects.enter('attentionSequence');\n    return inside(code);\n  }\n\n  /**\n   * In a sequence.\n   *\n   * ```markdown\n   * > | **\n   *     ^^\n   * ```\n   *\n   * @type {State}\n   */\n  function inside(code) {\n    if (code === marker) {\n      effects.consume(code);\n      return inside;\n    }\n    const token = effects.exit('attentionSequence');\n\n    // To do: next major: move this to resolver, just like `markdown-rs`.\n    const after = classifyCharacter(code);\n\n    // Always populated by defaults.\n\n    const open = !after || after === 2 && before || attentionMarkers.includes(code);\n    const close = !before || before === 2 && after || attentionMarkers.includes(previous);\n    token._open = Boolean(marker === 42 ? open : open && (before || !close));\n    token._close = Boolean(marker === 42 ? close : close && (after || !open));\n    return ok(code);\n  }\n}\n\n/**\n * Move a point a bit.\n *\n * Note: `move` only works inside lines! It‚Äôs not possible to move past other\n * chunks (replacement characters, tabs, or line endings).\n *\n * @param {Point} point\n *   Point.\n * @param {number} offset\n *   Amount to move.\n * @returns {undefined}\n *   Nothing.\n */\nfunction movePoint(point, offset) {\n  point.column += offset;\n  point.offset += offset;\n  point._bufferIndex += offset;\n}","/**\n * @import {\n *   Construct,\n *   State,\n *   TokenizeContext,\n *   Tokenizer\n * } from 'micromark-util-types'\n */\n\nimport { asciiAlphanumeric, asciiAlpha, asciiAtext, asciiControl } from 'micromark-util-character';\n/** @type {Construct} */\nexport const autolink = {\n  name: 'autolink',\n  tokenize: tokenizeAutolink\n};\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n */\nfunction tokenizeAutolink(effects, ok, nok) {\n  let size = 0;\n  return start;\n\n  /**\n   * Start of an autolink.\n   *\n   * ```markdown\n   * > | a<https://example.com>b\n   *      ^\n   * > | a<user@example.com>b\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter(\"autolink\");\n    effects.enter(\"autolinkMarker\");\n    effects.consume(code);\n    effects.exit(\"autolinkMarker\");\n    effects.enter(\"autolinkProtocol\");\n    return open;\n  }\n\n  /**\n   * After `<`, at protocol or atext.\n   *\n   * ```markdown\n   * > | a<https://example.com>b\n   *       ^\n   * > | a<user@example.com>b\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function open(code) {\n    if (asciiAlpha(code)) {\n      effects.consume(code);\n      return schemeOrEmailAtext;\n    }\n    if (code === 64) {\n      return nok(code);\n    }\n    return emailAtext(code);\n  }\n\n  /**\n   * At second byte of protocol or atext.\n   *\n   * ```markdown\n   * > | a<https://example.com>b\n   *        ^\n   * > | a<user@example.com>b\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function schemeOrEmailAtext(code) {\n    // ASCII alphanumeric and `+`, `-`, and `.`.\n    if (code === 43 || code === 45 || code === 46 || asciiAlphanumeric(code)) {\n      // Count the previous alphabetical from `open` too.\n      size = 1;\n      return schemeInsideOrEmailAtext(code);\n    }\n    return emailAtext(code);\n  }\n\n  /**\n   * In ambiguous protocol or atext.\n   *\n   * ```markdown\n   * > | a<https://example.com>b\n   *        ^\n   * > | a<user@example.com>b\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function schemeInsideOrEmailAtext(code) {\n    if (code === 58) {\n      effects.consume(code);\n      size = 0;\n      return urlInside;\n    }\n\n    // ASCII alphanumeric and `+`, `-`, and `.`.\n    if ((code === 43 || code === 45 || code === 46 || asciiAlphanumeric(code)) && size++ < 32) {\n      effects.consume(code);\n      return schemeInsideOrEmailAtext;\n    }\n    size = 0;\n    return emailAtext(code);\n  }\n\n  /**\n   * After protocol, in URL.\n   *\n   * ```markdown\n   * > | a<https://example.com>b\n   *             ^\n   * ```\n   *\n   * @type {State}\n   */\n  function urlInside(code) {\n    if (code === 62) {\n      effects.exit(\"autolinkProtocol\");\n      effects.enter(\"autolinkMarker\");\n      effects.consume(code);\n      effects.exit(\"autolinkMarker\");\n      effects.exit(\"autolink\");\n      return ok;\n    }\n\n    // ASCII control, space, or `<`.\n    if (code === null || code === 32 || code === 60 || asciiControl(code)) {\n      return nok(code);\n    }\n    effects.consume(code);\n    return urlInside;\n  }\n\n  /**\n   * In email atext.\n   *\n   * ```markdown\n   * > | a<user.name@example.com>b\n   *              ^\n   * ```\n   *\n   * @type {State}\n   */\n  function emailAtext(code) {\n    if (code === 64) {\n      effects.consume(code);\n      return emailAtSignOrDot;\n    }\n    if (asciiAtext(code)) {\n      effects.consume(code);\n      return emailAtext;\n    }\n    return nok(code);\n  }\n\n  /**\n   * In label, after at-sign or dot.\n   *\n   * ```markdown\n   * > | a<user.name@example.com>b\n   *                 ^       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function emailAtSignOrDot(code) {\n    return asciiAlphanumeric(code) ? emailLabel(code) : nok(code);\n  }\n\n  /**\n   * In label, where `.` and `>` are allowed.\n   *\n   * ```markdown\n   * > | a<user.name@example.com>b\n   *                   ^\n   * ```\n   *\n   * @type {State}\n   */\n  function emailLabel(code) {\n    if (code === 46) {\n      effects.consume(code);\n      size = 0;\n      return emailAtSignOrDot;\n    }\n    if (code === 62) {\n      // Exit, then change the token type.\n      effects.exit(\"autolinkProtocol\").type = \"autolinkEmail\";\n      effects.enter(\"autolinkMarker\");\n      effects.consume(code);\n      effects.exit(\"autolinkMarker\");\n      effects.exit(\"autolink\");\n      return ok;\n    }\n    return emailValue(code);\n  }\n\n  /**\n   * In label, where `.` and `>` are *not* allowed.\n   *\n   * Though, this is also used in `emailLabel` to parse other values.\n   *\n   * ```markdown\n   * > | a<user.name@ex-ample.com>b\n   *                    ^\n   * ```\n   *\n   * @type {State}\n   */\n  function emailValue(code) {\n    // ASCII alphanumeric or `-`.\n    if ((code === 45 || asciiAlphanumeric(code)) && size++ < 63) {\n      const next = code === 45 ? emailValue : emailLabel;\n      effects.consume(code);\n      return next;\n    }\n    return nok(code);\n  }\n}","/**\n * @import {\n *   Construct,\n *   Exiter,\n *   State,\n *   TokenizeContext,\n *   Tokenizer\n * } from 'micromark-util-types'\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownSpace } from 'micromark-util-character';\n/** @type {Construct} */\nexport const blockQuote = {\n  continuation: {\n    tokenize: tokenizeBlockQuoteContinuation\n  },\n  exit,\n  name: 'blockQuote',\n  tokenize: tokenizeBlockQuoteStart\n};\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n */\nfunction tokenizeBlockQuoteStart(effects, ok, nok) {\n  const self = this;\n  return start;\n\n  /**\n   * Start of block quote.\n   *\n   * ```markdown\n   * > | > a\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    if (code === 62) {\n      const state = self.containerState;\n      if (!state.open) {\n        effects.enter(\"blockQuote\", {\n          _container: true\n        });\n        state.open = true;\n      }\n      effects.enter(\"blockQuotePrefix\");\n      effects.enter(\"blockQuoteMarker\");\n      effects.consume(code);\n      effects.exit(\"blockQuoteMarker\");\n      return after;\n    }\n    return nok(code);\n  }\n\n  /**\n   * After `>`, before optional whitespace.\n   *\n   * ```markdown\n   * > | > a\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function after(code) {\n    if (markdownSpace(code)) {\n      effects.enter(\"blockQuotePrefixWhitespace\");\n      effects.consume(code);\n      effects.exit(\"blockQuotePrefixWhitespace\");\n      effects.exit(\"blockQuotePrefix\");\n      return ok;\n    }\n    effects.exit(\"blockQuotePrefix\");\n    return ok(code);\n  }\n}\n\n/**\n * Start of block quote continuation.\n *\n * ```markdown\n *   | > a\n * > | > b\n *     ^\n * ```\n *\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n */\nfunction tokenizeBlockQuoteContinuation(effects, ok, nok) {\n  const self = this;\n  return contStart;\n\n  /**\n   * Start of block quote continuation.\n   *\n   * Also used to parse the first block quote opening.\n   *\n   * ```markdown\n   *   | > a\n   * > | > b\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function contStart(code) {\n    if (markdownSpace(code)) {\n      // Always populated by defaults.\n\n      return factorySpace(effects, contBefore, \"linePrefix\", self.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4)(code);\n    }\n    return contBefore(code);\n  }\n\n  /**\n   * At `>`, after optional whitespace.\n   *\n   * Also used to parse the first block quote opening.\n   *\n   * ```markdown\n   *   | > a\n   * > | > b\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function contBefore(code) {\n    return effects.attempt(blockQuote, ok, nok)(code);\n  }\n}\n\n/** @type {Exiter} */\nfunction exit(effects) {\n  effects.exit(\"blockQuote\");\n}","/**\n * @import {\n *   Construct,\n *   State,\n *   TokenizeContext,\n *   Tokenizer\n * } from 'micromark-util-types'\n */\n\nimport { asciiPunctuation } from 'micromark-util-character';\n/** @type {Construct} */\nexport const characterEscape = {\n  name: 'characterEscape',\n  tokenize: tokenizeCharacterEscape\n};\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n */\nfunction tokenizeCharacterEscape(effects, ok, nok) {\n  return start;\n\n  /**\n   * Start of character escape.\n   *\n   * ```markdown\n   * > | a\\*b\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter(\"characterEscape\");\n    effects.enter(\"escapeMarker\");\n    effects.consume(code);\n    effects.exit(\"escapeMarker\");\n    return inside;\n  }\n\n  /**\n   * After `\\`, at punctuation.\n   *\n   * ```markdown\n   * > | a\\*b\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function inside(code) {\n    // ASCII punctuation.\n    if (asciiPunctuation(code)) {\n      effects.enter(\"characterEscapeValue\");\n      effects.consume(code);\n      effects.exit(\"characterEscapeValue\");\n      effects.exit(\"characterEscape\");\n      return ok;\n    }\n    return nok(code);\n  }\n}","/**\n * @import {\n *   Code,\n *   Construct,\n *   State,\n *   TokenizeContext,\n *   Tokenizer\n * } from 'micromark-util-types'\n */\n\nimport { decodeNamedCharacterReference } from 'decode-named-character-reference';\nimport { asciiAlphanumeric, asciiDigit, asciiHexDigit } from 'micromark-util-character';\n/** @type {Construct} */\nexport const characterReference = {\n  name: 'characterReference',\n  tokenize: tokenizeCharacterReference\n};\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n */\nfunction tokenizeCharacterReference(effects, ok, nok) {\n  const self = this;\n  let size = 0;\n  /** @type {number} */\n  let max;\n  /** @type {(code: Code) => boolean} */\n  let test;\n  return start;\n\n  /**\n   * Start of character reference.\n   *\n   * ```markdown\n   * > | a&amp;b\n   *      ^\n   * > | a&#123;b\n   *      ^\n   * > | a&#x9;b\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter(\"characterReference\");\n    effects.enter(\"characterReferenceMarker\");\n    effects.consume(code);\n    effects.exit(\"characterReferenceMarker\");\n    return open;\n  }\n\n  /**\n   * After `&`, at `#` for numeric references or alphanumeric for named\n   * references.\n   *\n   * ```markdown\n   * > | a&amp;b\n   *       ^\n   * > | a&#123;b\n   *       ^\n   * > | a&#x9;b\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function open(code) {\n    if (code === 35) {\n      effects.enter(\"characterReferenceMarkerNumeric\");\n      effects.consume(code);\n      effects.exit(\"characterReferenceMarkerNumeric\");\n      return numeric;\n    }\n    effects.enter(\"characterReferenceValue\");\n    max = 31;\n    test = asciiAlphanumeric;\n    return value(code);\n  }\n\n  /**\n   * After `#`, at `x` for hexadecimals or digit for decimals.\n   *\n   * ```markdown\n   * > | a&#123;b\n   *        ^\n   * > | a&#x9;b\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function numeric(code) {\n    if (code === 88 || code === 120) {\n      effects.enter(\"characterReferenceMarkerHexadecimal\");\n      effects.consume(code);\n      effects.exit(\"characterReferenceMarkerHexadecimal\");\n      effects.enter(\"characterReferenceValue\");\n      max = 6;\n      test = asciiHexDigit;\n      return value;\n    }\n    effects.enter(\"characterReferenceValue\");\n    max = 7;\n    test = asciiDigit;\n    return value(code);\n  }\n\n  /**\n   * After markers (`&#x`, `&#`, or `&`), in value, before `;`.\n   *\n   * The character reference kind defines what and how many characters are\n   * allowed.\n   *\n   * ```markdown\n   * > | a&amp;b\n   *       ^^^\n   * > | a&#123;b\n   *        ^^^\n   * > | a&#x9;b\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function value(code) {\n    if (code === 59 && size) {\n      const token = effects.exit(\"characterReferenceValue\");\n      if (test === asciiAlphanumeric && !decodeNamedCharacterReference(self.sliceSerialize(token))) {\n        return nok(code);\n      }\n\n      // To do: `markdown-rs` uses a different name:\n      // `CharacterReferenceMarkerSemi`.\n      effects.enter(\"characterReferenceMarker\");\n      effects.consume(code);\n      effects.exit(\"characterReferenceMarker\");\n      effects.exit(\"characterReference\");\n      return ok;\n    }\n    if (test(code) && size++ < max) {\n      effects.consume(code);\n      return value;\n    }\n    return nok(code);\n  }\n}","/**\n * @import {\n *   Code,\n *   Construct,\n *   State,\n *   TokenizeContext,\n *   Tokenizer\n * } from 'micromark-util-types'\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding, markdownSpace } from 'micromark-util-character';\n/** @type {Construct} */\nconst nonLazyContinuation = {\n  partial: true,\n  tokenize: tokenizeNonLazyContinuation\n};\n\n/** @type {Construct} */\nexport const codeFenced = {\n  concrete: true,\n  name: 'codeFenced',\n  tokenize: tokenizeCodeFenced\n};\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n */\nfunction tokenizeCodeFenced(effects, ok, nok) {\n  const self = this;\n  /** @type {Construct} */\n  const closeStart = {\n    partial: true,\n    tokenize: tokenizeCloseStart\n  };\n  let initialPrefix = 0;\n  let sizeOpen = 0;\n  /** @type {NonNullable<Code>} */\n  let marker;\n  return start;\n\n  /**\n   * Start of code.\n   *\n   * ```markdown\n   * > | ~~~js\n   *     ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    // To do: parse whitespace like `markdown-rs`.\n    return beforeSequenceOpen(code);\n  }\n\n  /**\n   * In opening fence, after prefix, at sequence.\n   *\n   * ```markdown\n   * > | ~~~js\n   *     ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function beforeSequenceOpen(code) {\n    const tail = self.events[self.events.length - 1];\n    initialPrefix = tail && tail[1].type === \"linePrefix\" ? tail[2].sliceSerialize(tail[1], true).length : 0;\n    marker = code;\n    effects.enter(\"codeFenced\");\n    effects.enter(\"codeFencedFence\");\n    effects.enter(\"codeFencedFenceSequence\");\n    return sequenceOpen(code);\n  }\n\n  /**\n   * In opening fence sequence.\n   *\n   * ```markdown\n   * > | ~~~js\n   *      ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function sequenceOpen(code) {\n    if (code === marker) {\n      sizeOpen++;\n      effects.consume(code);\n      return sequenceOpen;\n    }\n    if (sizeOpen < 3) {\n      return nok(code);\n    }\n    effects.exit(\"codeFencedFenceSequence\");\n    return markdownSpace(code) ? factorySpace(effects, infoBefore, \"whitespace\")(code) : infoBefore(code);\n  }\n\n  /**\n   * In opening fence, after the sequence (and optional whitespace), before info.\n   *\n   * ```markdown\n   * > | ~~~js\n   *        ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function infoBefore(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit(\"codeFencedFence\");\n      return self.interrupt ? ok(code) : effects.check(nonLazyContinuation, atNonLazyBreak, after)(code);\n    }\n    effects.enter(\"codeFencedFenceInfo\");\n    effects.enter(\"chunkString\", {\n      contentType: \"string\"\n    });\n    return info(code);\n  }\n\n  /**\n   * In info.\n   *\n   * ```markdown\n   * > | ~~~js\n   *        ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function info(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit(\"chunkString\");\n      effects.exit(\"codeFencedFenceInfo\");\n      return infoBefore(code);\n    }\n    if (markdownSpace(code)) {\n      effects.exit(\"chunkString\");\n      effects.exit(\"codeFencedFenceInfo\");\n      return factorySpace(effects, metaBefore, \"whitespace\")(code);\n    }\n    if (code === 96 && code === marker) {\n      return nok(code);\n    }\n    effects.consume(code);\n    return info;\n  }\n\n  /**\n   * In opening fence, after info and whitespace, before meta.\n   *\n   * ```markdown\n   * > | ~~~js eval\n   *           ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function metaBefore(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return infoBefore(code);\n    }\n    effects.enter(\"codeFencedFenceMeta\");\n    effects.enter(\"chunkString\", {\n      contentType: \"string\"\n    });\n    return meta(code);\n  }\n\n  /**\n   * In meta.\n   *\n   * ```markdown\n   * > | ~~~js eval\n   *           ^\n   *   | alert(1)\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function meta(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit(\"chunkString\");\n      effects.exit(\"codeFencedFenceMeta\");\n      return infoBefore(code);\n    }\n    if (code === 96 && code === marker) {\n      return nok(code);\n    }\n    effects.consume(code);\n    return meta;\n  }\n\n  /**\n   * At eol/eof in code, before a non-lazy closing fence or content.\n   *\n   * ```markdown\n   * > | ~~~js\n   *          ^\n   * > | alert(1)\n   *             ^\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function atNonLazyBreak(code) {\n    return effects.attempt(closeStart, after, contentBefore)(code);\n  }\n\n  /**\n   * Before code content, not a closing fence, at eol.\n   *\n   * ```markdown\n   *   | ~~~js\n   * > | alert(1)\n   *             ^\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function contentBefore(code) {\n    effects.enter(\"lineEnding\");\n    effects.consume(code);\n    effects.exit(\"lineEnding\");\n    return contentStart;\n  }\n\n  /**\n   * Before code content, not a closing fence.\n   *\n   * ```markdown\n   *   | ~~~js\n   * > | alert(1)\n   *     ^\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function contentStart(code) {\n    return initialPrefix > 0 && markdownSpace(code) ? factorySpace(effects, beforeContentChunk, \"linePrefix\", initialPrefix + 1)(code) : beforeContentChunk(code);\n  }\n\n  /**\n   * Before code content, after optional prefix.\n   *\n   * ```markdown\n   *   | ~~~js\n   * > | alert(1)\n   *     ^\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function beforeContentChunk(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return effects.check(nonLazyContinuation, atNonLazyBreak, after)(code);\n    }\n    effects.enter(\"codeFlowValue\");\n    return contentChunk(code);\n  }\n\n  /**\n   * In code content.\n   *\n   * ```markdown\n   *   | ~~~js\n   * > | alert(1)\n   *     ^^^^^^^^\n   *   | ~~~\n   * ```\n   *\n   * @type {State}\n   */\n  function contentChunk(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit(\"codeFlowValue\");\n      return beforeContentChunk(code);\n    }\n    effects.consume(code);\n    return contentChunk;\n  }\n\n  /**\n   * After code.\n   *\n   * ```markdown\n   *   | ~~~js\n   *   | alert(1)\n   * > | ~~~\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function after(code) {\n    effects.exit(\"codeFenced\");\n    return ok(code);\n  }\n\n  /**\n   * @this {TokenizeContext}\n   *   Context.\n   * @type {Tokenizer}\n   */\n  function tokenizeCloseStart(effects, ok, nok) {\n    let size = 0;\n    return startBefore;\n\n    /**\n     *\n     *\n     * @type {State}\n     */\n    function startBefore(code) {\n      effects.enter(\"lineEnding\");\n      effects.consume(code);\n      effects.exit(\"lineEnding\");\n      return start;\n    }\n\n    /**\n     * Before closing fence, at optional whitespace.\n     *\n     * ```markdown\n     *   | ~~~js\n     *   | alert(1)\n     * > | ~~~\n     *     ^\n     * ```\n     *\n     * @type {State}\n     */\n    function start(code) {\n      // Always populated by defaults.\n\n      // To do: `enter` here or in next state?\n      effects.enter(\"codeFencedFence\");\n      return markdownSpace(code) ? factorySpace(effects, beforeSequenceClose, \"linePrefix\", self.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4)(code) : beforeSequenceClose(code);\n    }\n\n    /**\n     * In closing fence, after optional whitespace, at sequence.\n     *\n     * ```markdown\n     *   | ~~~js\n     *   | alert(1)\n     * > | ~~~\n     *     ^\n     * ```\n     *\n     * @type {State}\n     */\n    function beforeSequenceClose(code) {\n      if (code === marker) {\n        effects.enter(\"codeFencedFenceSequence\");\n        return sequenceClose(code);\n      }\n      return nok(code);\n    }\n\n    /**\n     * In closing fence sequence.\n     *\n     * ```markdown\n     *   | ~~~js\n     *   | alert(1)\n     * > | ~~~\n     *     ^\n     * ```\n     *\n     * @type {State}\n     */\n    function sequenceClose(code) {\n      if (code === marker) {\n        size++;\n        effects.consume(code);\n        return sequenceClose;\n      }\n      if (size >= sizeOpen) {\n        effects.exit(\"codeFencedFenceSequence\");\n        return markdownSpace(code) ? factorySpace(effects, sequenceCloseAfter, \"whitespace\")(code) : sequenceCloseAfter(code);\n      }\n      return nok(code);\n    }\n\n    /**\n     * After closing fence sequence, after optional whitespace.\n     *\n     * ```markdown\n     *   | ~~~js\n     *   | alert(1)\n     * > | ~~~\n     *        ^\n     * ```\n     *\n     * @type {State}\n     */\n    function sequenceCloseAfter(code) {\n      if (code === null || markdownLineEnding(code)) {\n        effects.exit(\"codeFencedFence\");\n        return ok(code);\n      }\n      return nok(code);\n    }\n  }\n}\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n */\nfunction tokenizeNonLazyContinuation(effects, ok, nok) {\n  const self = this;\n  return start;\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function start(code) {\n    if (code === null) {\n      return nok(code);\n    }\n    effects.enter(\"lineEnding\");\n    effects.consume(code);\n    effects.exit(\"lineEnding\");\n    return lineStart;\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function lineStart(code) {\n    return self.parser.lazy[self.now().line] ? nok(code) : ok(code);\n  }\n}","/**\n * @import {\n *   Construct,\n *   State,\n *   TokenizeContext,\n *   Tokenizer\n * } from 'micromark-util-types'\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding, markdownSpace } from 'micromark-util-character';\n/** @type {Construct} */\nexport const codeIndented = {\n  name: 'codeIndented',\n  tokenize: tokenizeCodeIndented\n};\n\n/** @type {Construct} */\nconst furtherStart = {\n  partial: true,\n  tokenize: tokenizeFurtherStart\n};\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n */\nfunction tokenizeCodeIndented(effects, ok, nok) {\n  const self = this;\n  return start;\n\n  /**\n   * Start of code (indented).\n   *\n   * > **Parsing note**: it is not needed to check if this first line is a\n   * > filled line (that it has a non-whitespace character), because blank lines\n   * > are parsed already, so we never run into that.\n   *\n   * ```markdown\n   * > |     aaa\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    // To do: manually check if interrupting like `markdown-rs`.\n\n    effects.enter(\"codeIndented\");\n    // To do: use an improved `space_or_tab` function like `markdown-rs`,\n    // so that we can drop the next state.\n    return factorySpace(effects, afterPrefix, \"linePrefix\", 4 + 1)(code);\n  }\n\n  /**\n   * At start, after 1 or 4 spaces.\n   *\n   * ```markdown\n   * > |     aaa\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function afterPrefix(code) {\n    const tail = self.events[self.events.length - 1];\n    return tail && tail[1].type === \"linePrefix\" && tail[2].sliceSerialize(tail[1], true).length >= 4 ? atBreak(code) : nok(code);\n  }\n\n  /**\n   * At a break.\n   *\n   * ```markdown\n   * > |     aaa\n   *         ^  ^\n   * ```\n   *\n   * @type {State}\n   */\n  function atBreak(code) {\n    if (code === null) {\n      return after(code);\n    }\n    if (markdownLineEnding(code)) {\n      return effects.attempt(furtherStart, atBreak, after)(code);\n    }\n    effects.enter(\"codeFlowValue\");\n    return inside(code);\n  }\n\n  /**\n   * In code content.\n   *\n   * ```markdown\n   * > |     aaa\n   *         ^^^^\n   * ```\n   *\n   * @type {State}\n   */\n  function inside(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit(\"codeFlowValue\");\n      return atBreak(code);\n    }\n    effects.consume(code);\n    return inside;\n  }\n\n  /** @type {State} */\n  function after(code) {\n    effects.exit(\"codeIndented\");\n    // To do: allow interrupting like `markdown-rs`.\n    // Feel free to interrupt.\n    // tokenizer.interrupt = false\n    return ok(code);\n  }\n}\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n */\nfunction tokenizeFurtherStart(effects, ok, nok) {\n  const self = this;\n  return furtherStart;\n\n  /**\n   * At eol, trying to parse another indent.\n   *\n   * ```markdown\n   * > |     aaa\n   *            ^\n   *   |     bbb\n   * ```\n   *\n   * @type {State}\n   */\n  function furtherStart(code) {\n    // To do: improve `lazy` / `pierce` handling.\n    // If this is a lazy line, it can‚Äôt be code.\n    if (self.parser.lazy[self.now().line]) {\n      return nok(code);\n    }\n    if (markdownLineEnding(code)) {\n      effects.enter(\"lineEnding\");\n      effects.consume(code);\n      effects.exit(\"lineEnding\");\n      return furtherStart;\n    }\n\n    // To do: the code here in `micromark-js` is a bit different from\n    // `markdown-rs` because there it can attempt spaces.\n    // We can‚Äôt yet.\n    //\n    // To do: use an improved `space_or_tab` function like `markdown-rs`,\n    // so that we can drop the next state.\n    return factorySpace(effects, afterPrefix, \"linePrefix\", 4 + 1)(code);\n  }\n\n  /**\n   * At start, after 1 or 4 spaces.\n   *\n   * ```markdown\n   * > |     aaa\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function afterPrefix(code) {\n    const tail = self.events[self.events.length - 1];\n    return tail && tail[1].type === \"linePrefix\" && tail[2].sliceSerialize(tail[1], true).length >= 4 ? ok(code) : markdownLineEnding(code) ? furtherStart(code) : nok(code);\n  }\n}","/**\n * @import {\n *   Construct,\n *   Previous,\n *   Resolver,\n *   State,\n *   TokenizeContext,\n *   Tokenizer,\n *   Token\n * } from 'micromark-util-types'\n */\n\nimport { markdownLineEnding } from 'micromark-util-character';\n/** @type {Construct} */\nexport const codeText = {\n  name: 'codeText',\n  previous,\n  resolve: resolveCodeText,\n  tokenize: tokenizeCodeText\n};\n\n// To do: next major: don‚Äôt resolve, like `markdown-rs`.\n/** @type {Resolver} */\nfunction resolveCodeText(events) {\n  let tailExitIndex = events.length - 4;\n  let headEnterIndex = 3;\n  /** @type {number} */\n  let index;\n  /** @type {number | undefined} */\n  let enter;\n\n  // If we start and end with an EOL or a space.\n  if ((events[headEnterIndex][1].type === \"lineEnding\" || events[headEnterIndex][1].type === 'space') && (events[tailExitIndex][1].type === \"lineEnding\" || events[tailExitIndex][1].type === 'space')) {\n    index = headEnterIndex;\n\n    // And we have data.\n    while (++index < tailExitIndex) {\n      if (events[index][1].type === \"codeTextData\") {\n        // Then we have padding.\n        events[headEnterIndex][1].type = \"codeTextPadding\";\n        events[tailExitIndex][1].type = \"codeTextPadding\";\n        headEnterIndex += 2;\n        tailExitIndex -= 2;\n        break;\n      }\n    }\n  }\n\n  // Merge adjacent spaces and data.\n  index = headEnterIndex - 1;\n  tailExitIndex++;\n  while (++index <= tailExitIndex) {\n    if (enter === undefined) {\n      if (index !== tailExitIndex && events[index][1].type !== \"lineEnding\") {\n        enter = index;\n      }\n    } else if (index === tailExitIndex || events[index][1].type === \"lineEnding\") {\n      events[enter][1].type = \"codeTextData\";\n      if (index !== enter + 2) {\n        events[enter][1].end = events[index - 1][1].end;\n        events.splice(enter + 2, index - enter - 2);\n        tailExitIndex -= index - enter - 2;\n        index = enter + 2;\n      }\n      enter = undefined;\n    }\n  }\n  return events;\n}\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Previous}\n */\nfunction previous(code) {\n  // If there is a previous code, there will always be a tail.\n  return code !== 96 || this.events[this.events.length - 1][1].type === \"characterEscape\";\n}\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n */\nfunction tokenizeCodeText(effects, ok, nok) {\n  const self = this;\n  let sizeOpen = 0;\n  /** @type {number} */\n  let size;\n  /** @type {Token} */\n  let token;\n  return start;\n\n  /**\n   * Start of code (text).\n   *\n   * ```markdown\n   * > | `a`\n   *     ^\n   * > | \\`a`\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter(\"codeText\");\n    effects.enter(\"codeTextSequence\");\n    return sequenceOpen(code);\n  }\n\n  /**\n   * In opening sequence.\n   *\n   * ```markdown\n   * > | `a`\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function sequenceOpen(code) {\n    if (code === 96) {\n      effects.consume(code);\n      sizeOpen++;\n      return sequenceOpen;\n    }\n    effects.exit(\"codeTextSequence\");\n    return between(code);\n  }\n\n  /**\n   * Between something and something else.\n   *\n   * ```markdown\n   * > | `a`\n   *      ^^\n   * ```\n   *\n   * @type {State}\n   */\n  function between(code) {\n    // EOF.\n    if (code === null) {\n      return nok(code);\n    }\n\n    // To do: next major: don‚Äôt do spaces in resolve, but when compiling,\n    // like `markdown-rs`.\n    // Tabs don‚Äôt work, and virtual spaces don‚Äôt make sense.\n    if (code === 32) {\n      effects.enter('space');\n      effects.consume(code);\n      effects.exit('space');\n      return between;\n    }\n\n    // Closing fence? Could also be data.\n    if (code === 96) {\n      token = effects.enter(\"codeTextSequence\");\n      size = 0;\n      return sequenceClose(code);\n    }\n    if (markdownLineEnding(code)) {\n      effects.enter(\"lineEnding\");\n      effects.consume(code);\n      effects.exit(\"lineEnding\");\n      return between;\n    }\n\n    // Data.\n    effects.enter(\"codeTextData\");\n    return data(code);\n  }\n\n  /**\n   * In data.\n   *\n   * ```markdown\n   * > | `a`\n   *      ^\n   * ```\n   *\n   * @type {State}\n   */\n  function data(code) {\n    if (code === null || code === 32 || code === 96 || markdownLineEnding(code)) {\n      effects.exit(\"codeTextData\");\n      return between(code);\n    }\n    effects.consume(code);\n    return data;\n  }\n\n  /**\n   * In closing sequence.\n   *\n   * ```markdown\n   * > | `a`\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function sequenceClose(code) {\n    // More.\n    if (code === 96) {\n      effects.consume(code);\n      size++;\n      return sequenceClose;\n    }\n\n    // Done!\n    if (size === sizeOpen) {\n      effects.exit(\"codeTextSequence\");\n      effects.exit(\"codeText\");\n      return ok(code);\n    }\n\n    // More or less accents: mark as data.\n    token.type = \"codeTextData\";\n    return data(code);\n  }\n}","/**\n * @import {\n *   Construct,\n *   Resolver,\n *   State,\n *   TokenizeContext,\n *   Tokenizer,\n *   Token\n * } from 'micromark-util-types'\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { subtokenize } from 'micromark-util-subtokenize';\n/**\n * No name because it must not be turned off.\n * @type {Construct}\n */\nexport const content = {\n  resolve: resolveContent,\n  tokenize: tokenizeContent\n};\n\n/** @type {Construct} */\nconst continuationConstruct = {\n  partial: true,\n  tokenize: tokenizeContinuation\n};\n\n/**\n * Content is transparent: it‚Äôs parsed right now. That way, definitions are also\n * parsed right now: before text in paragraphs (specifically, media) are parsed.\n *\n * @type {Resolver}\n */\nfunction resolveContent(events) {\n  subtokenize(events);\n  return events;\n}\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n */\nfunction tokenizeContent(effects, ok) {\n  /** @type {Token | undefined} */\n  let previous;\n  return chunkStart;\n\n  /**\n   * Before a content chunk.\n   *\n   * ```markdown\n   * > | abc\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function chunkStart(code) {\n    effects.enter(\"content\");\n    previous = effects.enter(\"chunkContent\", {\n      contentType: \"content\"\n    });\n    return chunkInside(code);\n  }\n\n  /**\n   * In a content chunk.\n   *\n   * ```markdown\n   * > | abc\n   *     ^^^\n   * ```\n   *\n   * @type {State}\n   */\n  function chunkInside(code) {\n    if (code === null) {\n      return contentEnd(code);\n    }\n\n    // To do: in `markdown-rs`, each line is parsed on its own, and everything\n    // is stitched together resolving.\n    if (markdownLineEnding(code)) {\n      return effects.check(continuationConstruct, contentContinue, contentEnd)(code);\n    }\n\n    // Data.\n    effects.consume(code);\n    return chunkInside;\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function contentEnd(code) {\n    effects.exit(\"chunkContent\");\n    effects.exit(\"content\");\n    return ok(code);\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function contentContinue(code) {\n    effects.consume(code);\n    effects.exit(\"chunkContent\");\n    previous.next = effects.enter(\"chunkContent\", {\n      contentType: \"content\",\n      previous\n    });\n    previous = previous.next;\n    return chunkInside;\n  }\n}\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n */\nfunction tokenizeContinuation(effects, ok, nok) {\n  const self = this;\n  return startLookahead;\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function startLookahead(code) {\n    effects.exit(\"chunkContent\");\n    effects.enter(\"lineEnding\");\n    effects.consume(code);\n    effects.exit(\"lineEnding\");\n    return factorySpace(effects, prefixed, \"linePrefix\");\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function prefixed(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return nok(code);\n    }\n\n    // Always populated by defaults.\n\n    const tail = self.events[self.events.length - 1];\n    if (!self.parser.constructs.disable.null.includes('codeIndented') && tail && tail[1].type === \"linePrefix\" && tail[2].sliceSerialize(tail[1], true).length >= 4) {\n      return ok(code);\n    }\n    return effects.interrupt(self.parser.constructs.flow, nok, ok)(code);\n  }\n}","/**\n * @import {\n *   Construct,\n *   State,\n *   TokenizeContext,\n *   Tokenizer\n * } from 'micromark-util-types'\n */\n\nimport { factoryDestination } from 'micromark-factory-destination';\nimport { factoryLabel } from 'micromark-factory-label';\nimport { factorySpace } from 'micromark-factory-space';\nimport { factoryTitle } from 'micromark-factory-title';\nimport { factoryWhitespace } from 'micromark-factory-whitespace';\nimport { markdownLineEndingOrSpace, markdownLineEnding, markdownSpace } from 'micromark-util-character';\nimport { normalizeIdentifier } from 'micromark-util-normalize-identifier';\n/** @type {Construct} */\nexport const definition = {\n  name: 'definition',\n  tokenize: tokenizeDefinition\n};\n\n/** @type {Construct} */\nconst titleBefore = {\n  partial: true,\n  tokenize: tokenizeTitleBefore\n};\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n */\nfunction tokenizeDefinition(effects, ok, nok) {\n  const self = this;\n  /** @type {string} */\n  let identifier;\n  return start;\n\n  /**\n   * At start of a definition.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    // Do not interrupt paragraphs (but do follow definitions).\n    // To do: do `interrupt` the way `markdown-rs` does.\n    // To do: parse whitespace the way `markdown-rs` does.\n    effects.enter(\"definition\");\n    return before(code);\n  }\n\n  /**\n   * After optional whitespace, at `[`.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function before(code) {\n    // To do: parse whitespace the way `markdown-rs` does.\n\n    return factoryLabel.call(self, effects, labelAfter,\n    // Note: we don‚Äôt need to reset the way `markdown-rs` does.\n    nok, \"definitionLabel\", \"definitionLabelMarker\", \"definitionLabelString\")(code);\n  }\n\n  /**\n   * After label.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function labelAfter(code) {\n    identifier = normalizeIdentifier(self.sliceSerialize(self.events[self.events.length - 1][1]).slice(1, -1));\n    if (code === 58) {\n      effects.enter(\"definitionMarker\");\n      effects.consume(code);\n      effects.exit(\"definitionMarker\");\n      return markerAfter;\n    }\n    return nok(code);\n  }\n\n  /**\n   * After marker.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *         ^\n   * ```\n   *\n   * @type {State}\n   */\n  function markerAfter(code) {\n    // Note: whitespace is optional.\n    return markdownLineEndingOrSpace(code) ? factoryWhitespace(effects, destinationBefore)(code) : destinationBefore(code);\n  }\n\n  /**\n   * Before destination.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *          ^\n   * ```\n   *\n   * @type {State}\n   */\n  function destinationBefore(code) {\n    return factoryDestination(effects, destinationAfter,\n    // Note: we don‚Äôt need to reset the way `markdown-rs` does.\n    nok, \"definitionDestination\", \"definitionDestinationLiteral\", \"definitionDestinationLiteralMarker\", \"definitionDestinationRaw\", \"definitionDestinationString\")(code);\n  }\n\n  /**\n   * After destination.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *           ^\n   * ```\n   *\n   * @type {State}\n   */\n  function destinationAfter(code) {\n    return effects.attempt(titleBefore, after, after)(code);\n  }\n\n  /**\n   * After definition.\n   *\n   * ```markdown\n   * > | [a]: b\n   *           ^\n   * > | [a]: b \"c\"\n   *               ^\n   * ```\n   *\n   * @type {State}\n   */\n  function after(code) {\n    return markdownSpace(code) ? factorySpace(effects, afterWhitespace, \"whitespace\")(code) : afterWhitespace(code);\n  }\n\n  /**\n   * After definition, after optional whitespace.\n   *\n   * ```markdown\n   * > | [a]: b\n   *           ^\n   * > | [a]: b \"c\"\n   *               ^\n   * ```\n   *\n   * @type {State}\n   */\n  function afterWhitespace(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit(\"definition\");\n\n      // Note: we don‚Äôt care about uniqueness.\n      // It‚Äôs likely that that doesn‚Äôt happen very frequently.\n      // It is more likely that it wastes precious time.\n      self.parser.defined.push(identifier);\n\n      // To do: `markdown-rs` interrupt.\n      // // You‚Äôd be interrupting.\n      // tokenizer.interrupt = true\n      return ok(code);\n    }\n    return nok(code);\n  }\n}\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n */\nfunction tokenizeTitleBefore(effects, ok, nok) {\n  return titleBefore;\n\n  /**\n   * After destination, at whitespace.\n   *\n   * ```markdown\n   * > | [a]: b\n   *           ^\n   * > | [a]: b \"c\"\n   *           ^\n   * ```\n   *\n   * @type {State}\n   */\n  function titleBefore(code) {\n    return markdownLineEndingOrSpace(code) ? factoryWhitespace(effects, beforeMarker)(code) : nok(code);\n  }\n\n  /**\n   * At title.\n   *\n   * ```markdown\n   *   | [a]: b\n   * > | \"c\"\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function beforeMarker(code) {\n    return factoryTitle(effects, titleAfter, nok, \"definitionTitle\", \"definitionTitleMarker\", \"definitionTitleString\")(code);\n  }\n\n  /**\n   * After title.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *               ^\n   * ```\n   *\n   * @type {State}\n   */\n  function titleAfter(code) {\n    return markdownSpace(code) ? factorySpace(effects, titleAfterOptionalWhitespace, \"whitespace\")(code) : titleAfterOptionalWhitespace(code);\n  }\n\n  /**\n   * After title, after optional whitespace.\n   *\n   * ```markdown\n   * > | [a]: b \"c\"\n   *               ^\n   * ```\n   *\n   * @type {State}\n   */\n  function titleAfterOptionalWhitespace(code) {\n    return code === null || markdownLineEnding(code) ? ok(code) : nok(code);\n  }\n}","/**\n * @import {\n *   Construct,\n *   State,\n *   TokenizeContext,\n *   Tokenizer\n * } from 'micromark-util-types'\n */\n\nimport { markdownLineEnding } from 'micromark-util-character';\n/** @type {Construct} */\nexport const hardBreakEscape = {\n  name: 'hardBreakEscape',\n  tokenize: tokenizeHardBreakEscape\n};\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n */\nfunction tokenizeHardBreakEscape(effects, ok, nok) {\n  return start;\n\n  /**\n   * Start of a hard break (escape).\n   *\n   * ```markdown\n   * > | a\\\n   *      ^\n   *   | b\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    effects.enter(\"hardBreakEscape\");\n    effects.consume(code);\n    return after;\n  }\n\n  /**\n   * After `\\`, at eol.\n   *\n   * ```markdown\n   * > | a\\\n   *       ^\n   *   | b\n   * ```\n   *\n   *  @type {State}\n   */\n  function after(code) {\n    if (markdownLineEnding(code)) {\n      effects.exit(\"hardBreakEscape\");\n      return ok(code);\n    }\n    return nok(code);\n  }\n}","/**\n * @import {\n *   Construct,\n *   Resolver,\n *   State,\n *   TokenizeContext,\n *   Tokenizer,\n *   Token\n * } from 'micromark-util-types'\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEndingOrSpace, markdownLineEnding, markdownSpace } from 'micromark-util-character';\nimport { splice } from 'micromark-util-chunked';\n/** @type {Construct} */\nexport const headingAtx = {\n  name: 'headingAtx',\n  resolve: resolveHeadingAtx,\n  tokenize: tokenizeHeadingAtx\n};\n\n/** @type {Resolver} */\nfunction resolveHeadingAtx(events, context) {\n  let contentEnd = events.length - 2;\n  let contentStart = 3;\n  /** @type {Token} */\n  let content;\n  /** @type {Token} */\n  let text;\n\n  // Prefix whitespace, part of the opening.\n  if (events[contentStart][1].type === \"whitespace\") {\n    contentStart += 2;\n  }\n\n  // Suffix whitespace, part of the closing.\n  if (contentEnd - 2 > contentStart && events[contentEnd][1].type === \"whitespace\") {\n    contentEnd -= 2;\n  }\n  if (events[contentEnd][1].type === \"atxHeadingSequence\" && (contentStart === contentEnd - 1 || contentEnd - 4 > contentStart && events[contentEnd - 2][1].type === \"whitespace\")) {\n    contentEnd -= contentStart + 1 === contentEnd ? 2 : 4;\n  }\n  if (contentEnd > contentStart) {\n    content = {\n      type: \"atxHeadingText\",\n      start: events[contentStart][1].start,\n      end: events[contentEnd][1].end\n    };\n    text = {\n      type: \"chunkText\",\n      start: events[contentStart][1].start,\n      end: events[contentEnd][1].end,\n      contentType: \"text\"\n    };\n    splice(events, contentStart, contentEnd - contentStart + 1, [['enter', content, context], ['enter', text, context], ['exit', text, context], ['exit', content, context]]);\n  }\n  return events;\n}\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n */\nfunction tokenizeHeadingAtx(effects, ok, nok) {\n  let size = 0;\n  return start;\n\n  /**\n   * Start of a heading (atx).\n   *\n   * ```markdown\n   * > | ## aa\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function start(code) {\n    // To do: parse indent like `markdown-rs`.\n    effects.enter(\"atxHeading\");\n    return before(code);\n  }\n\n  /**\n   * After optional whitespace, at `#`.\n   *\n   * ```markdown\n   * > | ## aa\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function before(code) {\n    effects.enter(\"atxHeadingSequence\");\n    return sequenceOpen(code);\n  }\n\n  /**\n   * In opening sequence.\n   *\n   * ```markdown\n   * > | ## aa\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function sequenceOpen(code) {\n    if (code === 35 && size++ < 6) {\n      effects.consume(code);\n      return sequenceOpen;\n    }\n\n    // Always at least one `#`.\n    if (code === null || markdownLineEndingOrSpace(code)) {\n      effects.exit(\"atxHeadingSequence\");\n      return atBreak(code);\n    }\n    return nok(code);\n  }\n\n  /**\n   * After something, before something else.\n   *\n   * ```markdown\n   * > | ## aa\n   *       ^\n   * ```\n   *\n   * @type {State}\n   */\n  function atBreak(code) {\n    if (code === 35) {\n      effects.enter(\"atxHeadingSequence\");\n      return sequenceFurther(code);\n    }\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit(\"atxHeading\");\n      // To do: interrupt like `markdown-rs`.\n      // // Feel free to interrupt.\n      // tokenizer.interrupt = false\n      return ok(code);\n    }\n    if (markdownSpace(code)) {\n      return factorySpace(effects, atBreak, \"whitespace\")(code);\n    }\n\n    // To do: generate `data` tokens, add the `text` token later.\n    // Needs edit map, see: `markdown.rs`.\n    effects.enter(\"atxHeadingText\");\n    return data(code);\n  }\n\n  /**\n   * In further sequence (after whitespace).\n   *\n   * Could be normal ‚Äúvisible‚Äù hashes in the heading or a final sequence.\n   *\n   * ```markdown\n   * > | ## aa ##\n   *           ^\n   * ```\n   *\n   * @type {State}\n   */\n  function sequenceFurther(code) {\n    if (code === 35) {\n      effects.consume(code);\n      return sequenceFurther;\n    }\n    effects.exit(\"atxHeadingSequence\");\n    return atBreak(code);\n  }\n\n  /**\n   * In text.\n   *\n   * ```markdown\n   * > | ## aa\n   *        ^\n   * ```\n   *\n   * @type {State}\n   */\n  function data(code) {\n    if (code === null || code === 35 || markdownLineEndingOrSpace(code)) {\n      effects.exit(\"atxHeadingText\");\n      return atBreak(code);\n    }\n    effects.consume(code);\n    return data;\n  }\n}","export { attention } from './lib/attention.js';\nexport { autolink } from './lib/autolink.js';\nexport { blankLine } from './lib/blank-line.js';\nexport { blockQuote } from './lib/block-quote.js';\nexport { characterEscape } from './lib/character-escape.js';\nexport { characterReference } from './lib/character-reference.js';\nexport { codeFenced } from './lib/code-fenced.js';\nexport { codeIndented } from './lib/code-indented.js';\nexport { codeText } from './lib/code-text.js';\nexport { content } from './lib/content.js';\nexport { definition } from './lib/definition.js';\nexport { hardBreakEscape } from './lib/hard-break-escape.js';\nexport { headingAtx } from './lib/heading-atx.js';\nexport { htmlFlow } from './lib/html-flow.js';\nexport { htmlText } from './lib/html-text.js';\nexport { labelEnd } from './lib/label-end.js';\nexport { labelStartImage } from './lib/label-start-image.js';\nexport { labelStartLink } from './lib/label-start-link.js';\nexport { lineEnding } from './lib/line-ending.js';\nexport { list } from './lib/list.js';\nexport { setextUnderline } from './lib/setext-underline.js';\nexport { thematicBreak } from './lib/thematic-break.js';"],"names":[],"sourceRoot":"","ignoreList":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]}