{"version":3,"file":"static/chunks/9005.9f04695da24ee7c2.js","mappings":"yIAqBe,cAGf,UAEA,UAKA,YACA,MAAW,OAAY,IACvB,sBACA,KAIA,6CACA,qDACK,CACL,CACA,mBE9BO,cACP,gBACA,cACA,YACA,IAEA,KAEA,QACA,OACA,6BACA,MAGA,sBACA,YAKA,OAFA,6BAEA,UACA,CAYA,kBACA,QACA,WAEA,MACA,uBAEA,oBACA,IACA,kBAEA,CAEA,MACA,yBAEA,oBACA,IACA,oBAEA,CAEA,0BACA,oEC+Ee,uBACf,aAIA,oBAEA,MACQ,QAAM,SAAQ,GADY,EACZ,EAAiB,CAEvC,KAH4C,EAG5C,UACA,EAMA,cAMA,MACM,QAAM,IAAQ,eAAkC,CAEtD,CACA,iBE7KA,qCAA6C,CAAE,SAAa,EAAC,EAC7D,SAAiB,QACjB,2BACA,cACA,YACA,+BACA,YAYA,gBACA,sBACA,EAIA,gBAA4C,uBAoB5C,YAAiB,CAhBjB,kBAlBA,QAoBA,CADA,aAA8B,MAlB9B,EADA,EAoBA,IAlBA,WACA,WAkBA,GAEA,kBASA,CANA,EAFA,cAEA,eAIA,gBAEA,aACA,yBCxCA,OAHA,wCACA,0BAA6C,WAC7C,EACwC,EAAQ,KAAiB,GACjE,EAAkB,EAAQ,KADqB,EAK/C,UAJyB,CAIzB,KACA,gBACA,uBAGA,8BAEA,MACA,2BAEA,CAAK,EAPL,CASA,CACA,YACA,mCCtBA,8CACA,0BAA6C,UAC7C,EACA,qCAA6C,CAAE,SAAa,EAAC,EAC7D,OAAe,CAgBf,cACA,WACA,0BACA,SAEA,uBACA,uBAcA,OAbA,cACA,0BACA,OAEA,aAAgB,WAAkB,EAClC,EACA,SAEA,GAEA,CADA,SACA,MAEA,CAAK,EACL,CACA,EApCA,QAA8C,EAAQ,IAAqB,aAAtB,mTEO9C,OACP,SASA,YACA,IAEA,EAFA,kDAMA,mBACA,cACA,cAGA,sBACA,aACA,qBACW,OAAY,mBACvB,EAGA,YAEA,OADA,qBACA,SAIA,KACA,2BACA,mBACA,UACA,CAAK,EAKL,OAJA,GACA,WAEA,IACA,SAIA,KACA,aACA,oBACA,oBACA,aACA,MACA,OACA,CAAQ,OAAkB,KAC1B,aACA,oBACA,IAIA,aACA,EACA,EApBA,EACA,EAdA,EACA,GAlBA,QAmDA,CA/DA,ECQa,EAAQ,CACrB,SAcA,KAfqB,IAerB,GACA,IAKA,EAEA,EAEA,EATA,OAEA,KACA,IAOA,SAGA,cAWA,eACA,WAEA,OADA,sBACA,mCACA,CAGA,WACA,CAGA,cAMA,GALA,IAKA,iCAWA,CAVA,oCACA,GACA,IAKA,sBACA,IAKA,UACA,+DACA,qBACA,KACA,CAEA,KAGA,QACA,wBACA,oBACA,MAEA,IAQA,MAJM,OAAM,mCAGZ,kBACA,IACA,CACA,WACA,CAGA,cAMA,iBAIA,MACA,YAMA,mDACA,WAQA,qEACA,CAIA,OADA,oBACA,iBACA,CAGA,cAGA,OAFA,OACA,KACA,IACA,CAGA,cAGA,OAFA,yCACA,iBACA,IACA,CAGA,cAGA,OADA,oBACA,mBACA,CAGA,cAIA,OAHA,IACA,8CAEA,IACA,CAGA,cACA,aACA,OACA,KACA,aACA,MACA,CAOA,OANA,4BACA,qBACA,aACA,mBACA,UACA,CAAK,EAKL,cACA,aACA,0BACA,KACA,aACA,MACA,OACQ,QAAkB,KAC1B,aACA,uBAEA,IACA,mBACA,IAEA,aACA,EACA,EArBA,EACA,CA8BA,gBACA,uBAyCA,GAxCA,gBACA,aACA,cACA,IACA,sBACA,WAmCA,6BACA,IAoBA,EAEA,EAtBA,kBACA,UACA,GAEA,+BAEA,sBAEA,6BAGA,OAMA,sBACA,IAOA,UACA,+DACA,MACA,qBACA,KACA,CACA,IACA,CAMA,IAJA,KAGA,IACA,mBACA,oBACA,MAEA,IAIM,OAAM,mCAGZ,iBACA,CACA,CAQA,cACA,eAGA,cACA,UACA,uBACA,mBACA,CACA,UACA,CACA,aACA,gBACA,SACA,SACA,kCACA,CACA,CApUA,EAGA,GACA,SAwUA,gBAGA,MAAS,OAAY,qIACrB,CA3UA,iBCjBO,OACP,SASA,YACA,WACA,YAEE,IAAS,CAMX,mBACA,cACA,cAGA,2BACA,aACA,0BACA,0BACA,EACA,EAdA,+CAAsE,OAAY,qDAAuF,IAAO,qBAChL,SAgBA,qBACA,cACA,cAGA,sBACA,aACA,qBACA,0BACA,EACA,CACA,CA1CA,ECJO,GACP,cACA,EACO,cACM,EAAI,UAQjB,cACA,OACA,kCACA,SAQA,YACA,WACA,4BACA,mBACA,SAGA,cACA,qBACA,CAGA,qBACA,cACA,cAGA,gBACA,aACA,EACA,CAGA,qBACA,MACA,eACA,OAIA,aACA,EACA,CAQA,cACA,YACA,SAEA,WACA,KACA,KAGA,oBACA,WACA,8CACA,QAEA,CAEA,QACA,CACA,CAjEA,CAkEA,CAQA,cACA,OAGA,cACA,IAEA,EAFA,KAMA,oBACA,WACA,8BACA,IACA,KAEQ,8BAER,UACA,0BACA,oBACA,OAEA,UAGA,iBACA,CACA,CAaA,gBACA,QAEA,CAFsB,IAEtB,eACA,yEACA,IAMA,EANA,YACA,mBACA,WACA,KACA,IAGA,WACA,WACA,uBAEA,IADA,WACA,wBACA,IACA,IAEA,WACA,IACA,MAEA,UACA,KACA,SACU,eAEA,CAEV,IACA,KACA,CACA,CAMA,GAHA,0CACA,MAEA,GACA,OACA,2DACA,OACA,wCACA,wBACA,gBACA,sBACA,qBACA,CAAW,CACX,KACA,SAEA,CACA,QACA,UACA,EACA,8BACA,oBAEA,yCACA,KAEA,CACA,GACA,CAEA,QACA,CC3MO,IAAM,EAAQ,CACrB,GAAQ,IAAI,CACZ,GAAQ,IAAI,CAFS,GAGb,IAAI,CACZ,GAAQ,IAAI,CACZ,GAAQ,IAAI,CACZ,GAAQ,IAAI,CACZ,GAAQ,IAAI,CACZ,GAAQ,IAAI,CACZ,GAAQ,IAAI,CACZ,GAAQ,IAAI,CACZ,GAAQ,IAAI,CACZ,GAAQ,IAAI,CACZ,GAAQ,IAAI,CACZ,GAAQ,IAAU,EAIX,GACP,GAAQ,IAAU,EAIX,GACP,KAAQ,IAAY,CACpB,KAAQ,IAAY,CACpB,GAAQ,IAAY,EAIP,EAAI,CACjB,GAAQ,IAAU,CAClB,GAAQ,CAFS,CAET,EAAa,CACrB,IAAS,IAAe,CAAE,IAAa,EACvC,GAAQ,IAAQ,CAChB,GAAQ,IAAe,CACvB,GAAQ,IAAa,CACrB,GAAQ,IAAU,CAClB,IAAS,IAAU,EAIN,EAAM,CACnB,GAAQ,IAAkB,CAC1B,GAAQ,GAFW,CAEI,EAIV,EAAI,CACjB,KAAQ,IAAU,CAClB,EAFiB,EAEjB,CAAQ,IAAU,CAClB,KAAQ,IAAU,CAClB,GAAQ,IAAe,CACvB,GAAQ,IAAkB,CAC1B,GAAQ,IAAS,CACjB,IAAS,IAAQ,CAAE,IAAQ,EAC3B,GAAQ,IAAc,CACtB,IAAS,IAAe,CAAE,IAAe,EACzC,GAAQ,IAAQ,CAChB,GAAQ,IAAS,CACjB,GAAQ,IAAQ,EAIT,GACP,MAAS,IAAS,CAAE,EACpB,EAGO,GACP,CAL+B,IAK/B,SAIO,GACP,OACA,iBE5DO,SAAS,EAAK,GAMrB,MANqB,CAOrB,WAJE,OAAiB,EAAE,KAAiB,CAFtC,OAEsC,iBAKtC,UAAoB,GACpB,IAD2B,IAC3B,GACA,WAAqB,GACrB,OAAiB,GACjB,CADqB,GADQ,CAE7B,EAAY,CACZ,SAAmB,GACnB,GADyB,EACzB,EAAiB,EACjB,EACA,KAFqB,EAErB,EAQA,cACA,OAEA,YACA,OAAa,SDQN,MCRqB,CDU5B,OACA,gBACA,SACA,kBACA,sBACA,qBACA,EAEA,KAEA,KAEA,KAEA,KASA,GACA,UAoNA,cACA,WACA,GArNA,WACA,QAsJA,YACQ,QAAkB,KAC1B,SACA,WACA,qBACA,KACM,SACN,WACA,YAIA,iBACA,YAEA,iBAGA,iBAIA,qBACA,kBACA,aAKA,YAIA,EAtLA,MAyLA,cAGA,YAKA,OAJA,SACA,YACA,6BACA,UACA,CACA,EAjMA,KAoMA,YACA,cAGA,OAFA,UACA,4BACA,CACA,EAxMA,eACA,YACA,CAAK,CACL,EAOA,GACA,UACA,iBAAsB,CACtB,WA8EA,YACA,mBACA,GACA,EAhFA,UACA,MACA,SACA,cACA,eA4CA,cACA,OAuZA,cACA,IAIA,EAJA,KAEA,KAGA,oBACA,IAEA,EAFA,OAGA,sBACA,SACM,UACN,QAEA,OACA,KAEA,SAEA,OACA,KAEA,SAEA,SACA,KAEA,SAEA,YACA,KAEA,SAEA,kBACA,MACA,KAEA,SAGA,wBAEA,CACA,SACA,SACA,CACA,iBACA,EAxcA,OACA,EA7CA,cACA,MAsBA,kBAKA,CAJA,EAAa,OAAI,MACjB,WAqEA,MACA,yBACA,kBAGA,sBAKA,IAJA,WACA,kBACA,mBAEA,uCACA,KAgBA,IAhBA,6BAmBA,MAnBA,MAmBA,IAhBA,EAEA,CACA,IAnFA,sBACA,IAEA,OAGA,SAAqB,OAAU,eAC/B,SACA,CAlCA,EAOA,uBAWA,OAHA,cACA,UAEA,EA4BA,cACA,gBA2WA,KACA,IAKA,EALA,iBACA,uBACA,eACA,qBAGA,SAEA,wBACI,CAEJ,GADA,eACA,MACA,WACA,mBACA,gBAGA,SAEA,CACA,KAEA,uBAEA,CACA,QACA,EAtYA,IACA,CAGA,aAEA,IACA,eACA,SACA,OACA,SACA,SACA,CAAM,EACN,OACA,eACA,SACA,OACA,SACA,QACA,CACA,CAgIA,gBACA,WACA,CAUA,gBACA,OAeA,oBAsBA,EApBA,MAEA,EAEA,EAEA,EACA,wBACA,oBAEA,GAAqD,KAUrD,EAVqD,EAcrD,GAd0C,MAc1C,GACA,EAfqD,EAerD,iBACA,mBAKA,SAJA,IAGA,6DACA,EACA,GAWA,oBAGA,CAFA,IACA,IACA,cACA,EAEA,OACA,CAUA,cACA,OAGA,kBAaA,CARA,EAgEA,WACA,UACA,aACA,qBACA,kBACA,gBACA,OACA,OACA,QASA,WACA,IACA,aACA,qBACA,kBACA,IACA,GACA,CAfA,CAgBA,IAxFA,IACA,WACA,uBAKA,2DACA,KAEA,gBAIA,+CACA,CACA,CAGA,cAGA,OADA,OACA,CACA,CAGA,oBAGA,CADA,YACA,cACA,QAEA,CACA,CACA,CACA,CAUA,gBACA,8BACA,UAEA,WACM,OAAM,8DAEZ,aACA,kCAEA,CA0CA,aACA,0BACA,mBACA,sBAEA,CACA,EC1c4B,MAC5B,CACA,CACA,gBC3CO,SAAS,EAAW,GAC3B,MAAU,OAAW,KADM,CAI3B,QACA,CCAA,oBAMO,SAAS,IAChB,IAKA,EALA,IACA,KAEA,EAJ0B,CAI1B,EAGA,OAIA,gBAEA,IAEA,EAEA,EAEA,EAEA,EAEA,EAVA,KAqBA,IAVA,2EACA,IACA,KACA,IAEA,yBACA,IAEA,UAEA,aAKA,GAJA,cAEA,EADA,eACA,kCACA,kBACA,IACA,aACA,KACA,CACA,oBACA,WACA,cAUA,OARA,IACA,WACA,UAEA,MACA,qBACA,QAEA,GACA,OAEA,cACA,IACA,KAEA,QAIA,IAFA,mBACA,WACA,kBACA,KAEA,SAEA,WACA,IACA,KAEA,SAEA,KACA,GAEA,CAEA,KACA,CAMA,OALA,IACA,cACA,aACA,cAEA,CACA,CACA","sources":["webpack://_N_E/./node_modules/remark-parse/lib/index.js","webpack://_N_E/./node_modules/remark-parse/index.js","webpack://_N_E/./node_modules/trim-lines/index.js","webpack://_N_E/./node_modules/remark-rehype/lib/index.js","webpack://_N_E/./node_modules/remark-rehype/index.js","webpack://_N_E/./node_modules/style-to-js/cjs/utilities.js","webpack://_N_E/./node_modules/style-to-js/cjs/index.js","webpack://_N_E/./node_modules/style-to-object/cjs/index.js","webpack://_N_E/./node_modules/micromark/lib/compile.js","webpack://_N_E/./node_modules/micromark/lib/initialize/content.js","webpack://_N_E/./node_modules/micromark/lib/initialize/document.js","webpack://_N_E/./node_modules/micromark/lib/initialize/flow.js","webpack://_N_E/./node_modules/micromark/lib/initialize/text.js","webpack://_N_E/./node_modules/micromark/lib/constructs.js","webpack://_N_E/./node_modules/micromark/lib/create-tokenizer.js","webpack://_N_E/./node_modules/micromark/lib/parse.js","webpack://_N_E/./node_modules/micromark/lib/postprocess.js","webpack://_N_E/./node_modules/micromark/lib/preprocess.js","webpack://_N_E/./node_modules/micromark/index.js"],"sourcesContent":["/**\n * @typedef {import('mdast').Root} Root\n * @typedef {import('mdast-util-from-markdown').Options} FromMarkdownOptions\n * @typedef {import('unified').Parser<Root>} Parser\n * @typedef {import('unified').Processor<Root>} Processor\n */\n\n/**\n * @typedef {Omit<FromMarkdownOptions, 'extensions' | 'mdastExtensions'>} Options\n */\n\nimport {fromMarkdown} from 'mdast-util-from-markdown'\n\n/**\n * Aadd support for parsing from markdown.\n *\n * @param {Readonly<Options> | null | undefined} [options]\n *   Configuration (optional).\n * @returns {undefined}\n *   Nothing.\n */\nexport default function remarkParse(options) {\n  /** @type {Processor} */\n  // @ts-expect-error: TS in JSDoc generates wrong types if `this` is typed regularly.\n  const self = this\n\n  self.parser = parser\n\n  /**\n   * @type {Parser}\n   */\n  function parser(doc) {\n    return fromMarkdown(doc, {\n      ...self.data('settings'),\n      ...options,\n      // Note: these options are not in the readme.\n      // The goal is for them to be set by plugins on `data` instead of being\n      // passed by users.\n      extensions: self.data('micromarkExtensions') || [],\n      mdastExtensions: self.data('fromMarkdownExtensions') || []\n    })\n  }\n}\n","// Note: types exposed from `index.d.ts`.\nexport {default} from './lib/index.js'\n","const tab = 9 /* `\\t` */\nconst space = 32 /* ` ` */\n\n/**\n * Remove initial and final spaces and tabs at the line breaks in `value`.\n * Does not trim initial and final spaces and tabs of the value itself.\n *\n * @param {string} value\n *   Value to trim.\n * @returns {string}\n *   Trimmed value.\n */\nexport function trimLines(value) {\n  const source = String(value)\n  const search = /\\r?\\n|\\r/g\n  let match = search.exec(source)\n  let last = 0\n  /** @type {Array<string>} */\n  const lines = []\n\n  while (match) {\n    lines.push(\n      trimLine(source.slice(last, match.index), last > 0, true),\n      match[0]\n    )\n\n    last = match.index + match[0].length\n    match = search.exec(source)\n  }\n\n  lines.push(trimLine(source.slice(last), last > 0, false))\n\n  return lines.join('')\n}\n\n/**\n * @param {string} value\n *   Line to trim.\n * @param {boolean} start\n *   Whether to trim the start of the line.\n * @param {boolean} end\n *   Whether to trim the end of the line.\n * @returns {string}\n *   Trimmed line.\n */\nfunction trimLine(value, start, end) {\n  let startIndex = 0\n  let endIndex = value.length\n\n  if (start) {\n    let code = value.codePointAt(startIndex)\n\n    while (code === tab || code === space) {\n      startIndex++\n      code = value.codePointAt(startIndex)\n    }\n  }\n\n  if (end) {\n    let code = value.codePointAt(endIndex - 1)\n\n    while (code === tab || code === space) {\n      endIndex--\n      code = value.codePointAt(endIndex - 1)\n    }\n  }\n\n  return endIndex > startIndex ? value.slice(startIndex, endIndex) : ''\n}\n","/**\n * @import {Root as HastRoot} from 'hast'\n * @import {Root as MdastRoot} from 'mdast'\n * @import {Options as ToHastOptions} from 'mdast-util-to-hast'\n * @import {Processor} from 'unified'\n * @import {VFile} from 'vfile'\n */\n\n/**\n * @typedef {Omit<ToHastOptions, 'file'>} Options\n *\n * @callback TransformBridge\n *   Bridge-mode.\n *\n *   Runs the destination with the new hast tree.\n *   Discards result.\n * @param {MdastRoot} tree\n *   Tree.\n * @param {VFile} file\n *   File.\n * @returns {Promise<undefined>}\n *   Nothing.\n *\n * @callback TransformMutate\n *  Mutate-mode.\n *\n *  Further transformers run on the hast tree.\n * @param {MdastRoot} tree\n *   Tree.\n * @param {VFile} file\n *   File.\n * @returns {HastRoot}\n *   Tree (hast).\n */\n\nimport {toHast} from 'mdast-util-to-hast'\n\n/**\n * Turn markdown into HTML.\n *\n * ##### Notes\n *\n * ###### Signature\n *\n * * if a processor is given,\n *   runs the (rehype) plugins used on it with a hast tree,\n *   then discards the result (*bridge mode*)\n * * otherwise,\n *   returns a hast tree,\n *   the plugins used after `remarkRehype` are rehype plugins (*mutate mode*)\n *\n * > üëâ **Note**:\n * > It‚Äôs highly unlikely that you want to pass a `processor`.\n *\n * ###### HTML\n *\n * Raw HTML is available in mdast as `html` nodes and can be embedded in hast\n * as semistandard `raw` nodes.\n * Most plugins ignore `raw` nodes but two notable ones don‚Äôt:\n *\n * * `rehype-stringify` also has an option `allowDangerousHtml` which will\n *   output the raw HTML.\n *   This is typically discouraged as noted by the option name but is useful if\n *   you completely trust authors\n * * `rehype-raw` can handle the raw embedded HTML strings by parsing them\n *   into standard hast nodes (`element`, `text`, etc);\n *   this is a heavy task as it needs a full HTML parser,\n *   but it is the only way to support untrusted content\n *\n * ###### Footnotes\n *\n * Many options supported here relate to footnotes.\n * Footnotes are not specified by CommonMark,\n * which we follow by default.\n * They are supported by GitHub,\n * so footnotes can be enabled in markdown with `remark-gfm`.\n *\n * The options `footnoteBackLabel` and `footnoteLabel` define natural language\n * that explains footnotes,\n * which is hidden for sighted users but shown to assistive technology.\n * When your page is not in English,\n * you must define translated values.\n *\n * Back references use ARIA attributes,\n * but the section label itself uses a heading that is hidden with an\n * `sr-only` class.\n * To show it to sighted users,\n * define different attributes in `footnoteLabelProperties`.\n *\n * ###### Clobbering\n *\n * Footnotes introduces a problem,\n * as it links footnote calls to footnote definitions on the page through `id`\n * attributes generated from user content,\n * which results in DOM clobbering.\n *\n * DOM clobbering is this:\n *\n * ```html\n * <p id=x></p>\n * <script>alert(x) // `x` now refers to the DOM `p#x` element</script>\n * ```\n *\n * Elements by their ID are made available by browsers on the `window` object,\n * which is a security risk.\n * Using a prefix solves this problem.\n *\n * More information on how to handle clobbering and the prefix is explained in\n * *Example: headings (DOM clobbering)* in `rehype-sanitize`.\n *\n * ###### Unknown nodes\n *\n * Unknown nodes are nodes with a type that isn‚Äôt in `handlers` or `passThrough`.\n * The default behavior for unknown nodes is:\n *\n * * when the node has a `value`\n *   (and doesn‚Äôt have `data.hName`, `data.hProperties`, or `data.hChildren`,\n *   see later),\n *   create a hast `text` node\n * * otherwise,\n *   create a `<div>` element (which could be changed with `data.hName`),\n *   with its children mapped from mdast to hast as well\n *\n * This behavior can be changed by passing an `unknownHandler`.\n *\n * @overload\n * @param {Processor} processor\n * @param {Readonly<Options> | null | undefined} [options]\n * @returns {TransformBridge}\n *\n * @overload\n * @param {Readonly<Options> | null | undefined} [options]\n * @returns {TransformMutate}\n *\n * @overload\n * @param {Readonly<Options> | Processor | null | undefined} [destination]\n * @param {Readonly<Options> | null | undefined} [options]\n * @returns {TransformBridge | TransformMutate}\n *\n * @param {Readonly<Options> | Processor | null | undefined} [destination]\n *   Processor or configuration (optional).\n * @param {Readonly<Options> | null | undefined} [options]\n *   When a processor was given,\n *   configuration (optional).\n * @returns {TransformBridge | TransformMutate}\n *   Transform.\n */\nexport default function remarkRehype(destination, options) {\n  if (destination && 'run' in destination) {\n    /**\n     * @type {TransformBridge}\n     */\n    return async function (tree, file) {\n      // Cast because root in -> root out.\n      const hastTree = /** @type {HastRoot} */ (\n        toHast(tree, {file, ...options})\n      )\n      await destination.run(hastTree, file)\n    }\n  }\n\n  /**\n   * @type {TransformMutate}\n   */\n  return function (tree, file) {\n    // Cast because root in -> root out.\n    // To do: in the future, disallow ` || options` fallback.\n    // With `unified-engine`, `destination` can be `undefined` but\n    // `options` will be the file set.\n    // We should not pass that as `options`.\n    return /** @type {HastRoot} */ (\n      toHast(tree, {file, ...(destination || options)})\n    )\n  }\n}\n","/**\n * @typedef {import('./lib/index.js').Options} Options\n */\n\nexport {\n  defaultFootnoteBackContent,\n  defaultFootnoteBackLabel,\n  defaultHandlers\n} from 'mdast-util-to-hast'\nexport {default} from './lib/index.js'\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.camelCase = void 0;\nvar CUSTOM_PROPERTY_REGEX = /^--[a-zA-Z0-9_-]+$/;\nvar HYPHEN_REGEX = /-([a-z])/g;\nvar NO_HYPHEN_REGEX = /^[^-]+$/;\nvar VENDOR_PREFIX_REGEX = /^-(webkit|moz|ms|o|khtml)-/;\nvar MS_VENDOR_PREFIX_REGEX = /^-(ms)-/;\n/**\n * Checks whether to skip camelCase.\n */\nvar skipCamelCase = function (property) {\n    return !property ||\n        NO_HYPHEN_REGEX.test(property) ||\n        CUSTOM_PROPERTY_REGEX.test(property);\n};\n/**\n * Replacer that capitalizes first character.\n */\nvar capitalize = function (match, character) {\n    return character.toUpperCase();\n};\n/**\n * Replacer that removes beginning hyphen of vendor prefix property.\n */\nvar trimHyphen = function (match, prefix) { return \"\".concat(prefix, \"-\"); };\n/**\n * CamelCases a CSS property.\n */\nvar camelCase = function (property, options) {\n    if (options === void 0) { options = {}; }\n    if (skipCamelCase(property)) {\n        return property;\n    }\n    property = property.toLowerCase();\n    if (options.reactCompat) {\n        // `-ms` vendor prefix should not be capitalized\n        property = property.replace(MS_VENDOR_PREFIX_REGEX, trimHyphen);\n    }\n    else {\n        // for non-React, remove first hyphen so vendor prefix is not capitalized\n        property = property.replace(VENDOR_PREFIX_REGEX, trimHyphen);\n    }\n    return property.replace(HYPHEN_REGEX, capitalize);\n};\nexports.camelCase = camelCase;\n//# sourceMappingURL=utilities.js.map","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nvar style_to_object_1 = __importDefault(require(\"style-to-object\"));\nvar utilities_1 = require(\"./utilities\");\n/**\n * Parses CSS inline style to JavaScript object (camelCased).\n */\nfunction StyleToJS(style, options) {\n    var output = {};\n    if (!style || typeof style !== 'string') {\n        return output;\n    }\n    (0, style_to_object_1.default)(style, function (property, value) {\n        // skip CSS comment\n        if (property && value) {\n            output[(0, utilities_1.camelCase)(property, options)] = value;\n        }\n    });\n    return output;\n}\nStyleToJS.default = StyleToJS;\nmodule.exports = StyleToJS;\n//# sourceMappingURL=index.js.map","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.default = StyleToObject;\nconst inline_style_parser_1 = __importDefault(require(\"inline-style-parser\"));\n/**\n * Parses inline style to object.\n *\n * @param style - Inline style.\n * @param iterator - Iterator.\n * @returns - Style object or null.\n *\n * @example Parsing inline style to object:\n *\n * ```js\n * import parse from 'style-to-object';\n * parse('line-height: 42;'); // { 'line-height': '42' }\n * ```\n */\nfunction StyleToObject(style, iterator) {\n    let styleObject = null;\n    if (!style || typeof style !== 'string') {\n        return styleObject;\n    }\n    const declarations = (0, inline_style_parser_1.default)(style);\n    const hasIterator = typeof iterator === 'function';\n    declarations.forEach((declaration) => {\n        if (declaration.type !== 'declaration') {\n            return;\n        }\n        const { property, value } = declaration;\n        if (hasIterator) {\n            iterator(property, value, declaration);\n        }\n        else if (value) {\n            styleObject = styleObject || {};\n            styleObject[property] = value;\n        }\n    });\n    return styleObject;\n}\n//# sourceMappingURL=index.js.map","/**\n * While micromark is a lexer/tokenizer, the common case of going from markdown\n * to html is currently built in as this module, even though the parts can be\n * used separately to build ASTs, CSTs, or many other output formats.\n *\n * Having an HTML compiler built in is useful because it allows us to check for\n * compliancy to CommonMark, the de facto norm of markdown, specified in roughly\n * 600 input/output cases.\n *\n * This module has an interface that accepts lists of events instead of the\n * whole at once, however, because markdown can‚Äôt be truly streaming, we buffer\n * events before processing and outputting the final result.\n */\n\n/**\n * @import {\n *   CompileContext,\n *   CompileData,\n *   CompileOptions,\n *   Compile,\n *   Definition,\n *   Event,\n *   Handle,\n *   HtmlExtension,\n *   LineEnding,\n *   NormalizedHtmlExtension,\n *   Token\n * } from 'micromark-util-types'\n */\n\n/**\n * @typedef Media\n * @property {boolean | undefined} [image]\n * @property {string | undefined} [labelId]\n * @property {string | undefined} [label]\n * @property {string | undefined} [referenceId]\n * @property {string | undefined} [destination]\n * @property {string | undefined} [title]\n */\n\nimport { decodeNamedCharacterReference } from 'decode-named-character-reference';\nimport { push } from 'micromark-util-chunked';\nimport { combineHtmlExtensions } from 'micromark-util-combine-extensions';\nimport { decodeNumericCharacterReference } from 'micromark-util-decode-numeric-character-reference';\nimport { encode as _encode } from 'micromark-util-encode';\nimport { normalizeIdentifier } from 'micromark-util-normalize-identifier';\nimport { sanitizeUri } from 'micromark-util-sanitize-uri';\nconst hasOwnProperty = {}.hasOwnProperty;\n\n/**\n * These two are allowlists of safe protocols for full URLs in respectively the\n * `href` (on `<a>`) and `src` (on `<img>`) attributes.\n * They are based on what is allowed on GitHub,\n * <https://github.com/syntax-tree/hast-util-sanitize/blob/9275b21/lib/github.json#L31>\n */\nconst protocolHref = /^(https?|ircs?|mailto|xmpp)$/i;\nconst protocolSource = /^https?$/i;\n\n/**\n * @param {CompileOptions | null | undefined} [options]\n * @returns {Compile}\n */\nexport function compile(options) {\n  const settings = options || {};\n\n  /**\n   * Tags is needed because according to markdown, links and emphasis and\n   * whatnot can exist in images, however, as HTML doesn‚Äôt allow content in\n   * images, the tags are ignored in the `alt` attribute, but the content\n   * remains.\n   *\n   * @type {boolean | undefined}\n   */\n  let tags = true;\n\n  /**\n   * An object to track identifiers to media (URLs and titles) defined with\n   * definitions.\n   *\n   * @type {Record<string, Definition>}\n   */\n  const definitions = {};\n\n  /**\n   * A lot of the handlers need to capture some of the output data, modify it\n   * somehow, and then deal with it.\n   * We do that by tracking a stack of buffers, that can be opened (with\n   * `buffer`) and closed (with `resume`) to access them.\n   *\n   * @type {Array<Array<string>>}\n   */\n  const buffers = [[]];\n\n  /**\n   * As we can have links in images and the other way around, where the deepest\n   * ones are closed first, we need to track which one we‚Äôre in.\n   *\n   * @type {Array<Media>}\n   */\n  const mediaStack = [];\n\n  /**\n   * Same as `mediaStack` for tightness, which is specific to lists.\n   * We need to track if we‚Äôre currently in a tight or loose container.\n   *\n   * @type {Array<boolean>}\n   */\n  const tightStack = [];\n\n  /** @type {HtmlExtension} */\n  const defaultHandlers = {\n    enter: {\n      blockQuote: onenterblockquote,\n      codeFenced: onentercodefenced,\n      codeFencedFenceInfo: buffer,\n      codeFencedFenceMeta: buffer,\n      codeIndented: onentercodeindented,\n      codeText: onentercodetext,\n      content: onentercontent,\n      definition: onenterdefinition,\n      definitionDestinationString: onenterdefinitiondestinationstring,\n      definitionLabelString: buffer,\n      definitionTitleString: buffer,\n      emphasis: onenteremphasis,\n      htmlFlow: onenterhtmlflow,\n      htmlText: onenterhtml,\n      image: onenterimage,\n      label: buffer,\n      link: onenterlink,\n      listItemMarker: onenterlistitemmarker,\n      listItemValue: onenterlistitemvalue,\n      listOrdered: onenterlistordered,\n      listUnordered: onenterlistunordered,\n      paragraph: onenterparagraph,\n      reference: buffer,\n      resource: onenterresource,\n      resourceDestinationString: onenterresourcedestinationstring,\n      resourceTitleString: buffer,\n      setextHeading: onentersetextheading,\n      strong: onenterstrong\n    },\n    exit: {\n      atxHeading: onexitatxheading,\n      atxHeadingSequence: onexitatxheadingsequence,\n      autolinkEmail: onexitautolinkemail,\n      autolinkProtocol: onexitautolinkprotocol,\n      blockQuote: onexitblockquote,\n      characterEscapeValue: onexitdata,\n      characterReferenceMarkerHexadecimal: onexitcharacterreferencemarker,\n      characterReferenceMarkerNumeric: onexitcharacterreferencemarker,\n      characterReferenceValue: onexitcharacterreferencevalue,\n      codeFenced: onexitflowcode,\n      codeFencedFence: onexitcodefencedfence,\n      codeFencedFenceInfo: onexitcodefencedfenceinfo,\n      codeFencedFenceMeta: onresumedrop,\n      codeFlowValue: onexitcodeflowvalue,\n      codeIndented: onexitflowcode,\n      codeText: onexitcodetext,\n      codeTextData: onexitdata,\n      data: onexitdata,\n      definition: onexitdefinition,\n      definitionDestinationString: onexitdefinitiondestinationstring,\n      definitionLabelString: onexitdefinitionlabelstring,\n      definitionTitleString: onexitdefinitiontitlestring,\n      emphasis: onexitemphasis,\n      hardBreakEscape: onexithardbreak,\n      hardBreakTrailing: onexithardbreak,\n      htmlFlow: onexithtml,\n      htmlFlowData: onexitdata,\n      htmlText: onexithtml,\n      htmlTextData: onexitdata,\n      image: onexitmedia,\n      label: onexitlabel,\n      labelText: onexitlabeltext,\n      lineEnding: onexitlineending,\n      link: onexitmedia,\n      listOrdered: onexitlistordered,\n      listUnordered: onexitlistunordered,\n      paragraph: onexitparagraph,\n      reference: onresumedrop,\n      referenceString: onexitreferencestring,\n      resource: onresumedrop,\n      resourceDestinationString: onexitresourcedestinationstring,\n      resourceTitleString: onexitresourcetitlestring,\n      setextHeading: onexitsetextheading,\n      setextHeadingLineSequence: onexitsetextheadinglinesequence,\n      setextHeadingText: onexitsetextheadingtext,\n      strong: onexitstrong,\n      thematicBreak: onexitthematicbreak\n    }\n  };\n\n  /**\n   * Combine the HTML extensions with the default handlers.\n   * An HTML extension is an object whose fields are either `enter` or `exit`\n   * (reflecting whether a token is entered or exited).\n   * The values at such objects are names of tokens mapping to handlers.\n   * Handlers are called, respectively when a token is opener or closed, with\n   * that token, and a context as `this`.\n   */\n  const handlers = /** @type {NormalizedHtmlExtension} */\n  combineHtmlExtensions([defaultHandlers, ...(settings.htmlExtensions || [])]);\n\n  /**\n   * Handlers do often need to keep track of some state.\n   * That state is provided here as a key-value store (an object).\n   *\n   * @type {CompileData}\n   */\n  const data = {\n    definitions,\n    tightStack\n  };\n\n  /**\n   * The context for handlers references a couple of useful functions.\n   * In handlers from extensions, those can be accessed at `this`.\n   * For the handlers here, they can be accessed directly.\n   *\n   * @type {Omit<CompileContext, 'sliceSerialize'>}\n   */\n  const context = {\n    buffer,\n    encode,\n    getData,\n    lineEndingIfNeeded,\n    options: settings,\n    raw,\n    resume,\n    setData,\n    tag\n  };\n\n  /**\n   * Generally, micromark copies line endings (`'\\r'`, `'\\n'`, `'\\r\\n'`) in the\n   * markdown document over to the compiled HTML.\n   * In some cases, such as `> a`, CommonMark requires that extra line endings\n   * are added: `<blockquote>\\n<p>a</p>\\n</blockquote>`.\n   * This variable hold the default line ending when given (or `undefined`),\n   * and in the latter case will be updated to the first found line ending if\n   * there is one.\n   */\n  let lineEndingStyle = settings.defaultLineEnding;\n\n  // Return the function that handles a slice of events.\n  return compile;\n\n  /**\n   * Deal w/ a slice of events.\n   * Return either the empty string if there‚Äôs nothing of note to return, or the\n   * result when done.\n   *\n   * @param {ReadonlyArray<Event>} events\n   * @returns {string}\n   */\n  function compile(events) {\n    let index = -1;\n    let start = 0;\n    /** @type {Array<number>} */\n    const listStack = [];\n    // As definitions can come after references, we need to figure out the media\n    // (urls and titles) defined by them before handling the references.\n    // So, we do sort of what HTML does: put metadata at the start (in head), and\n    // then put content after (`body`).\n    /** @type {Array<Event>} */\n    let head = [];\n    /** @type {Array<Event>} */\n    let body = [];\n    while (++index < events.length) {\n      // Figure out the line ending style used in the document.\n      if (!lineEndingStyle && (events[index][1].type === \"lineEnding\" || events[index][1].type === \"lineEndingBlank\")) {\n        lineEndingStyle = /** @type {LineEnding} */\n        events[index][2].sliceSerialize(events[index][1]);\n      }\n\n      // Preprocess lists to infer whether the list is loose or not.\n      if (events[index][1].type === \"listOrdered\" || events[index][1].type === \"listUnordered\") {\n        if (events[index][0] === 'enter') {\n          listStack.push(index);\n        } else {\n          prepareList(events.slice(listStack.pop(), index));\n        }\n      }\n\n      // Move definitions to the front.\n      if (events[index][1].type === \"definition\") {\n        if (events[index][0] === 'enter') {\n          body = push(body, events.slice(start, index));\n          start = index;\n        } else {\n          head = push(head, events.slice(start, index + 1));\n          start = index + 1;\n        }\n      }\n    }\n    head = push(head, body);\n    head = push(head, events.slice(start));\n    index = -1;\n    const result = head;\n\n    // Handle the start of the document, if defined.\n    if (handlers.enter.null) {\n      handlers.enter.null.call(context);\n    }\n\n    // Handle all events.\n    while (++index < events.length) {\n      const handles = handlers[result[index][0]];\n      const kind = result[index][1].type;\n      const handle = handles[kind];\n      if (hasOwnProperty.call(handles, kind) && handle) {\n        handle.call({\n          sliceSerialize: result[index][2].sliceSerialize,\n          ...context\n        }, result[index][1]);\n      }\n    }\n\n    // Handle the end of the document, if defined.\n    if (handlers.exit.null) {\n      handlers.exit.null.call(context);\n    }\n    return buffers[0].join('');\n  }\n\n  /**\n   * Figure out whether lists are loose or not.\n   *\n   * @param {ReadonlyArray<Event>} slice\n   * @returns {undefined}\n   */\n  function prepareList(slice) {\n    const length = slice.length;\n    let index = 0; // Skip open.\n    let containerBalance = 0;\n    let loose = false;\n    /** @type {boolean | undefined} */\n    let atMarker;\n    while (++index < length) {\n      const event = slice[index];\n      if (event[1]._container) {\n        atMarker = undefined;\n        if (event[0] === 'enter') {\n          containerBalance++;\n        } else {\n          containerBalance--;\n        }\n      } else switch (event[1].type) {\n        case \"listItemPrefix\":\n          {\n            if (event[0] === 'exit') {\n              atMarker = true;\n            }\n            break;\n          }\n        case \"linePrefix\":\n          {\n            // Ignore\n\n            break;\n          }\n        case \"lineEndingBlank\":\n          {\n            if (event[0] === 'enter' && !containerBalance) {\n              if (atMarker) {\n                atMarker = undefined;\n              } else {\n                loose = true;\n              }\n            }\n            break;\n          }\n        default:\n          {\n            atMarker = undefined;\n          }\n      }\n    }\n    slice[0][1]._loose = loose;\n  }\n\n  /**\n   * @type {CompileContext['setData']}\n   */\n  function setData(key, value) {\n    // @ts-expect-error: assume `value` is omitted (`undefined` is passed) only\n    // if allowed.\n    data[key] = value;\n  }\n\n  /**\n   * @type {CompileContext['getData']}\n   */\n  function getData(key) {\n    return data[key];\n  }\n\n  /** @type {CompileContext['buffer']} */\n  function buffer() {\n    buffers.push([]);\n  }\n\n  /** @type {CompileContext['resume']} */\n  function resume() {\n    const buf = buffers.pop();\n    return buf.join('');\n  }\n\n  /** @type {CompileContext['tag']} */\n  function tag(value) {\n    if (!tags) return;\n    setData('lastWasTag', true);\n    buffers[buffers.length - 1].push(value);\n  }\n\n  /** @type {CompileContext['raw']} */\n  function raw(value) {\n    setData('lastWasTag');\n    buffers[buffers.length - 1].push(value);\n  }\n\n  /**\n   * Output an extra line ending.\n   *\n   * @returns {undefined}\n   */\n  function lineEnding() {\n    raw(lineEndingStyle || '\\n');\n  }\n\n  /** @type {CompileContext['lineEndingIfNeeded']} */\n  function lineEndingIfNeeded() {\n    const buffer = buffers[buffers.length - 1];\n    const slice = buffer[buffer.length - 1];\n    const previous = slice ? slice.charCodeAt(slice.length - 1) : null;\n    if (previous === 10 || previous === 13 || previous === null) {\n      return;\n    }\n    lineEnding();\n  }\n\n  /** @type {CompileContext['encode']} */\n  function encode(value) {\n    return getData('ignoreEncode') ? value : _encode(value);\n  }\n\n  //\n  // Handlers.\n  //\n\n  /**\n   * @returns {undefined}\n   */\n  function onresumedrop() {\n    resume();\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterlistordered(token) {\n    tightStack.push(!token._loose);\n    lineEndingIfNeeded();\n    tag('<ol');\n    setData('expectFirstItem', true);\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterlistunordered(token) {\n    tightStack.push(!token._loose);\n    lineEndingIfNeeded();\n    tag('<ul');\n    setData('expectFirstItem', true);\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterlistitemvalue(token) {\n    if (getData('expectFirstItem')) {\n      const value = Number.parseInt(this.sliceSerialize(token), 10);\n      if (value !== 1) {\n        tag(' start=\"' + encode(String(value)) + '\"');\n      }\n    }\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onenterlistitemmarker() {\n    if (getData('expectFirstItem')) {\n      tag('>');\n    } else {\n      onexitlistitem();\n    }\n    lineEndingIfNeeded();\n    tag('<li>');\n    setData('expectFirstItem');\n    // ‚ÄúHack‚Äù to prevent a line ending from showing up if the item is empty.\n    setData('lastWasTag');\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onexitlistordered() {\n    onexitlistitem();\n    tightStack.pop();\n    lineEnding();\n    tag('</ol>');\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onexitlistunordered() {\n    onexitlistitem();\n    tightStack.pop();\n    lineEnding();\n    tag('</ul>');\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onexitlistitem() {\n    if (getData('lastWasTag') && !getData('slurpAllLineEndings')) {\n      lineEndingIfNeeded();\n    }\n    tag('</li>');\n    setData('slurpAllLineEndings');\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterblockquote() {\n    tightStack.push(false);\n    lineEndingIfNeeded();\n    tag('<blockquote>');\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitblockquote() {\n    tightStack.pop();\n    lineEndingIfNeeded();\n    tag('</blockquote>');\n    setData('slurpAllLineEndings');\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterparagraph() {\n    if (!tightStack[tightStack.length - 1]) {\n      lineEndingIfNeeded();\n      tag('<p>');\n    }\n    setData('slurpAllLineEndings');\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitparagraph() {\n    if (tightStack[tightStack.length - 1]) {\n      setData('slurpAllLineEndings', true);\n    } else {\n      tag('</p>');\n    }\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onentercodefenced() {\n    lineEndingIfNeeded();\n    tag('<pre><code');\n    setData('fencesCount', 0);\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcodefencedfenceinfo() {\n    const value = resume();\n    tag(' class=\"language-' + value + '\"');\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcodefencedfence() {\n    const count = getData('fencesCount') || 0;\n    if (!count) {\n      tag('>');\n      setData('slurpOneLineEnding', true);\n    }\n    setData('fencesCount', count + 1);\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onentercodeindented() {\n    lineEndingIfNeeded();\n    tag('<pre><code>');\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitflowcode() {\n    const count = getData('fencesCount');\n\n    // One special case is if we are inside a container, and the fenced code was\n    // not closed (meaning it runs to the end).\n    // In that case, the following line ending, is considered *outside* the\n    // fenced code and block quote by micromark, but CM wants to treat that\n    // ending as part of the code.\n    if (count !== undefined && count < 2 && data.tightStack.length > 0 && !getData('lastWasTag')) {\n      lineEnding();\n    }\n\n    // But in most cases, it‚Äôs simpler: when we‚Äôve seen some data, emit an extra\n    // line ending when needed.\n    if (getData('flowCodeSeenData')) {\n      lineEndingIfNeeded();\n    }\n    tag('</code></pre>');\n    if (count !== undefined && count < 2) lineEndingIfNeeded();\n    setData('flowCodeSeenData');\n    setData('fencesCount');\n    setData('slurpOneLineEnding');\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterimage() {\n    mediaStack.push({\n      image: true\n    });\n    tags = undefined; // Disallow tags.\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterlink() {\n    mediaStack.push({});\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitlabeltext(token) {\n    mediaStack[mediaStack.length - 1].labelId = this.sliceSerialize(token);\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitlabel() {\n    mediaStack[mediaStack.length - 1].label = resume();\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitreferencestring(token) {\n    mediaStack[mediaStack.length - 1].referenceId = this.sliceSerialize(token);\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterresource() {\n    buffer(); // We can have line endings in the resource, ignore them.\n    mediaStack[mediaStack.length - 1].destination = '';\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterresourcedestinationstring() {\n    buffer();\n    // Ignore encoding the result, as we‚Äôll first percent encode the url and\n    // encode manually after.\n    setData('ignoreEncode', true);\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitresourcedestinationstring() {\n    mediaStack[mediaStack.length - 1].destination = resume();\n    setData('ignoreEncode');\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitresourcetitlestring() {\n    mediaStack[mediaStack.length - 1].title = resume();\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitmedia() {\n    let index = mediaStack.length - 1; // Skip current.\n    const media = mediaStack[index];\n    const id = media.referenceId || media.labelId;\n    const context = media.destination === undefined ? definitions[normalizeIdentifier(id)] : media;\n    tags = true;\n    while (index--) {\n      if (mediaStack[index].image) {\n        tags = undefined;\n        break;\n      }\n    }\n    if (media.image) {\n      tag('<img src=\"' + sanitizeUri(context.destination, settings.allowDangerousProtocol ? undefined : protocolSource) + '\" alt=\"');\n      raw(media.label);\n      tag('\"');\n    } else {\n      tag('<a href=\"' + sanitizeUri(context.destination, settings.allowDangerousProtocol ? undefined : protocolHref) + '\"');\n    }\n    tag(context.title ? ' title=\"' + context.title + '\"' : '');\n    if (media.image) {\n      tag(' />');\n    } else {\n      tag('>');\n      raw(media.label);\n      tag('</a>');\n    }\n    mediaStack.pop();\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterdefinition() {\n    buffer();\n    mediaStack.push({});\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitdefinitionlabelstring(token) {\n    // Discard label, use the source content instead.\n    resume();\n    mediaStack[mediaStack.length - 1].labelId = this.sliceSerialize(token);\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterdefinitiondestinationstring() {\n    buffer();\n    setData('ignoreEncode', true);\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitdefinitiondestinationstring() {\n    mediaStack[mediaStack.length - 1].destination = resume();\n    setData('ignoreEncode');\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitdefinitiontitlestring() {\n    mediaStack[mediaStack.length - 1].title = resume();\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitdefinition() {\n    const media = mediaStack[mediaStack.length - 1];\n    const id = normalizeIdentifier(media.labelId);\n    resume();\n    if (!hasOwnProperty.call(definitions, id)) {\n      definitions[id] = mediaStack[mediaStack.length - 1];\n    }\n    mediaStack.pop();\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onentercontent() {\n    setData('slurpAllLineEndings', true);\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitatxheadingsequence(token) {\n    // Exit for further sequences.\n    if (getData('headingRank')) return;\n    setData('headingRank', this.sliceSerialize(token).length);\n    lineEndingIfNeeded();\n    tag('<h' + getData('headingRank') + '>');\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onentersetextheading() {\n    buffer();\n    setData('slurpAllLineEndings');\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitsetextheadingtext() {\n    setData('slurpAllLineEndings', true);\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitatxheading() {\n    tag('</h' + getData('headingRank') + '>');\n    setData('headingRank');\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitsetextheadinglinesequence(token) {\n    setData('headingRank', this.sliceSerialize(token).charCodeAt(0) === 61 ? 1 : 2);\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitsetextheading() {\n    const value = resume();\n    lineEndingIfNeeded();\n    tag('<h' + getData('headingRank') + '>');\n    raw(value);\n    tag('</h' + getData('headingRank') + '>');\n    setData('slurpAllLineEndings');\n    setData('headingRank');\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitdata(token) {\n    raw(encode(this.sliceSerialize(token)));\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitlineending(token) {\n    if (getData('slurpAllLineEndings')) {\n      return;\n    }\n    if (getData('slurpOneLineEnding')) {\n      setData('slurpOneLineEnding');\n      return;\n    }\n    if (getData('inCodeText')) {\n      raw(' ');\n      return;\n    }\n    raw(encode(this.sliceSerialize(token)));\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcodeflowvalue(token) {\n    raw(encode(this.sliceSerialize(token)));\n    setData('flowCodeSeenData', true);\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexithardbreak() {\n    tag('<br />');\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onenterhtmlflow() {\n    lineEndingIfNeeded();\n    onenterhtml();\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onexithtml() {\n    setData('ignoreEncode');\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onenterhtml() {\n    if (settings.allowDangerousHtml) {\n      setData('ignoreEncode', true);\n    }\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onenteremphasis() {\n    tag('<em>');\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onenterstrong() {\n    tag('<strong>');\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onentercodetext() {\n    setData('inCodeText', true);\n    tag('<code>');\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onexitcodetext() {\n    setData('inCodeText');\n    tag('</code>');\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onexitemphasis() {\n    tag('</em>');\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onexitstrong() {\n    tag('</strong>');\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onexitthematicbreak() {\n    lineEndingIfNeeded();\n    tag('<hr />');\n  }\n\n  /**\n   * @this {CompileContext}\n   * @param {Token} token\n   * @returns {undefined}\n   */\n  function onexitcharacterreferencemarker(token) {\n    setData('characterReferenceType', token.type);\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcharacterreferencevalue(token) {\n    const value = this.sliceSerialize(token);\n    const decoded = getData('characterReferenceType') ? decodeNumericCharacterReference(value, getData('characterReferenceType') === \"characterReferenceMarkerNumeric\" ? 10 : 16) : decodeNamedCharacterReference(value);\n\n    // `decodeNamedCharacterReference` can return `false` for invalid named\n    // character references,\n    // but everything we‚Äôve tokenized is valid.\n    raw(encode(/** @type {string} */decoded));\n    setData('characterReferenceType');\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitautolinkprotocol(token) {\n    const uri = this.sliceSerialize(token);\n    tag('<a href=\"' + sanitizeUri(uri, settings.allowDangerousProtocol ? undefined : protocolHref) + '\">');\n    raw(encode(uri));\n    tag('</a>');\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitautolinkemail(token) {\n    const uri = this.sliceSerialize(token);\n    tag('<a href=\"' + sanitizeUri('mailto:' + uri) + '\">');\n    raw(encode(uri));\n    tag('</a>');\n  }\n}","/**\n * @import {\n *   InitialConstruct,\n *   Initializer,\n *   State,\n *   TokenizeContext,\n *   Token\n * } from 'micromark-util-types'\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\n/** @type {InitialConstruct} */\nexport const content = {\n  tokenize: initializeContent\n};\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Initializer}\n *   Content.\n */\nfunction initializeContent(effects) {\n  const contentStart = effects.attempt(this.parser.constructs.contentInitial, afterContentStartConstruct, paragraphInitial);\n  /** @type {Token} */\n  let previous;\n  return contentStart;\n\n  /** @type {State} */\n  function afterContentStartConstruct(code) {\n    if (code === null) {\n      effects.consume(code);\n      return;\n    }\n    effects.enter(\"lineEnding\");\n    effects.consume(code);\n    effects.exit(\"lineEnding\");\n    return factorySpace(effects, contentStart, \"linePrefix\");\n  }\n\n  /** @type {State} */\n  function paragraphInitial(code) {\n    effects.enter(\"paragraph\");\n    return lineStart(code);\n  }\n\n  /** @type {State} */\n  function lineStart(code) {\n    const token = effects.enter(\"chunkText\", {\n      contentType: \"text\",\n      previous\n    });\n    if (previous) {\n      previous.next = token;\n    }\n    previous = token;\n    return data(code);\n  }\n\n  /** @type {State} */\n  function data(code) {\n    if (code === null) {\n      effects.exit(\"chunkText\");\n      effects.exit(\"paragraph\");\n      effects.consume(code);\n      return;\n    }\n    if (markdownLineEnding(code)) {\n      effects.consume(code);\n      effects.exit(\"chunkText\");\n      return lineStart;\n    }\n\n    // Data.\n    effects.consume(code);\n    return data;\n  }\n}","/**\n * @import {\n *   Construct,\n *   ContainerState,\n *   InitialConstruct,\n *   Initializer,\n *   Point,\n *   State,\n *   TokenizeContext,\n *   Tokenizer,\n *   Token\n * } from 'micromark-util-types'\n */\n\n/**\n * @typedef {[Construct, ContainerState]} StackItem\n *   Construct and its state.\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { splice } from 'micromark-util-chunked';\n/** @type {InitialConstruct} */\nexport const document = {\n  tokenize: initializeDocument\n};\n\n/** @type {Construct} */\nconst containerConstruct = {\n  tokenize: tokenizeContainer\n};\n\n/**\n * @this {TokenizeContext}\n *   Self.\n * @type {Initializer}\n *   Initializer.\n */\nfunction initializeDocument(effects) {\n  const self = this;\n  /** @type {Array<StackItem>} */\n  const stack = [];\n  let continued = 0;\n  /** @type {TokenizeContext | undefined} */\n  let childFlow;\n  /** @type {Token | undefined} */\n  let childToken;\n  /** @type {number} */\n  let lineStartOffset;\n  return start;\n\n  /** @type {State} */\n  function start(code) {\n    // First we iterate through the open blocks, starting with the root\n    // document, and descending through last children down to the last open\n    // block.\n    // Each block imposes a condition that the line must satisfy if the block is\n    // to remain open.\n    // For example, a block quote requires a `>` character.\n    // A paragraph requires a non-blank line.\n    // In this phase we may match all or just some of the open blocks.\n    // But we cannot close unmatched blocks yet, because we may have a lazy\n    // continuation line.\n    if (continued < stack.length) {\n      const item = stack[continued];\n      self.containerState = item[1];\n      return effects.attempt(item[0].continuation, documentContinue, checkNewContainers)(code);\n    }\n\n    // Done.\n    return checkNewContainers(code);\n  }\n\n  /** @type {State} */\n  function documentContinue(code) {\n    continued++;\n\n    // Note: this field is called `_closeFlow` but it also closes containers.\n    // Perhaps a good idea to rename it but it‚Äôs already used in the wild by\n    // extensions.\n    if (self.containerState._closeFlow) {\n      self.containerState._closeFlow = undefined;\n      if (childFlow) {\n        closeFlow();\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when dealing with lazy lines in `writeToChild`.\n      const indexBeforeExits = self.events.length;\n      let indexBeforeFlow = indexBeforeExits;\n      /** @type {Point | undefined} */\n      let point;\n\n      // Find the flow chunk.\n      while (indexBeforeFlow--) {\n        if (self.events[indexBeforeFlow][0] === 'exit' && self.events[indexBeforeFlow][1].type === \"chunkFlow\") {\n          point = self.events[indexBeforeFlow][1].end;\n          break;\n        }\n      }\n      exitContainers(continued);\n\n      // Fix positions.\n      let index = indexBeforeExits;\n      while (index < self.events.length) {\n        self.events[index][1].end = {\n          ...point\n        };\n        index++;\n      }\n\n      // Inject the exits earlier (they‚Äôre still also at the end).\n      splice(self.events, indexBeforeFlow + 1, 0, self.events.slice(indexBeforeExits));\n\n      // Discard the duplicate exits.\n      self.events.length = index;\n      return checkNewContainers(code);\n    }\n    return start(code);\n  }\n\n  /** @type {State} */\n  function checkNewContainers(code) {\n    // Next, after consuming the continuation markers for existing blocks, we\n    // look for new block starts (e.g. `>` for a block quote).\n    // If we encounter a new block start, we close any blocks unmatched in\n    // step 1 before creating the new block as a child of the last matched\n    // block.\n    if (continued === stack.length) {\n      // No need to `check` whether there‚Äôs a container, of `exitContainers`\n      // would be moot.\n      // We can instead immediately `attempt` to parse one.\n      if (!childFlow) {\n        return documentContinued(code);\n      }\n\n      // If we have concrete content, such as block HTML or fenced code,\n      // we can‚Äôt have containers ‚Äúpierce‚Äù into them, so we can immediately\n      // start.\n      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {\n        return flowStart(code);\n      }\n\n      // If we do have flow, it could still be a blank line,\n      // but we‚Äôd be interrupting it w/ a new container if there‚Äôs a current\n      // construct.\n      // To do: next major: remove `_gfmTableDynamicInterruptHack` (no longer\n      // needed in micromark-extension-gfm-table@1.0.6).\n      self.interrupt = Boolean(childFlow.currentConstruct && !childFlow._gfmTableDynamicInterruptHack);\n    }\n\n    // Check if there is a new container.\n    self.containerState = {};\n    return effects.check(containerConstruct, thereIsANewContainer, thereIsNoNewContainer)(code);\n  }\n\n  /** @type {State} */\n  function thereIsANewContainer(code) {\n    if (childFlow) closeFlow();\n    exitContainers(continued);\n    return documentContinued(code);\n  }\n\n  /** @type {State} */\n  function thereIsNoNewContainer(code) {\n    self.parser.lazy[self.now().line] = continued !== stack.length;\n    lineStartOffset = self.now().offset;\n    return flowStart(code);\n  }\n\n  /** @type {State} */\n  function documentContinued(code) {\n    // Try new containers.\n    self.containerState = {};\n    return effects.attempt(containerConstruct, containerContinue, flowStart)(code);\n  }\n\n  /** @type {State} */\n  function containerContinue(code) {\n    continued++;\n    stack.push([self.currentConstruct, self.containerState]);\n    // Try another.\n    return documentContinued(code);\n  }\n\n  /** @type {State} */\n  function flowStart(code) {\n    if (code === null) {\n      if (childFlow) closeFlow();\n      exitContainers(0);\n      effects.consume(code);\n      return;\n    }\n    childFlow = childFlow || self.parser.flow(self.now());\n    effects.enter(\"chunkFlow\", {\n      _tokenizer: childFlow,\n      contentType: \"flow\",\n      previous: childToken\n    });\n    return flowContinue(code);\n  }\n\n  /** @type {State} */\n  function flowContinue(code) {\n    if (code === null) {\n      writeToChild(effects.exit(\"chunkFlow\"), true);\n      exitContainers(0);\n      effects.consume(code);\n      return;\n    }\n    if (markdownLineEnding(code)) {\n      effects.consume(code);\n      writeToChild(effects.exit(\"chunkFlow\"));\n      // Get ready for the next line.\n      continued = 0;\n      self.interrupt = undefined;\n      return start;\n    }\n    effects.consume(code);\n    return flowContinue;\n  }\n\n  /**\n   * @param {Token} token\n   *   Token.\n   * @param {boolean | undefined} [endOfFile]\n   *   Whether the token is at the end of the file (default: `false`).\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function writeToChild(token, endOfFile) {\n    const stream = self.sliceStream(token);\n    if (endOfFile) stream.push(null);\n    token.previous = childToken;\n    if (childToken) childToken.next = token;\n    childToken = token;\n    childFlow.defineSkip(token.start);\n    childFlow.write(stream);\n\n    // Alright, so we just added a lazy line:\n    //\n    // ```markdown\n    // > a\n    // b.\n    //\n    // Or:\n    //\n    // > ~~~c\n    // d\n    //\n    // Or:\n    //\n    // > | e |\n    // f\n    // ```\n    //\n    // The construct in the second example (fenced code) does not accept lazy\n    // lines, so it marked itself as done at the end of its first line, and\n    // then the content construct parses `d`.\n    // Most constructs in markdown match on the first line: if the first line\n    // forms a construct, a non-lazy line can‚Äôt ‚Äúunmake‚Äù it.\n    //\n    // The construct in the third example is potentially a GFM table, and\n    // those are *weird*.\n    // It *could* be a table, from the first line, if the following line\n    // matches a condition.\n    // In this case, that second line is lazy, which ‚Äúunmakes‚Äù the first line\n    // and turns the whole into one content block.\n    //\n    // We‚Äôve now parsed the non-lazy and the lazy line, and can figure out\n    // whether the lazy line started a new flow block.\n    // If it did, we exit the current containers between the two flow blocks.\n    if (self.parser.lazy[token.start.line]) {\n      let index = childFlow.events.length;\n      while (index--) {\n        if (\n        // The token starts before the line ending‚Ä¶\n        childFlow.events[index][1].start.offset < lineStartOffset && (\n        // ‚Ä¶and either is not ended yet‚Ä¶\n        !childFlow.events[index][1].end ||\n        // ‚Ä¶or ends after it.\n        childFlow.events[index][1].end.offset > lineStartOffset)) {\n          // Exit: there‚Äôs still something open, which means it‚Äôs a lazy line\n          // part of something.\n          return;\n        }\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when closing flow in `documentContinue`.\n      const indexBeforeExits = self.events.length;\n      let indexBeforeFlow = indexBeforeExits;\n      /** @type {boolean | undefined} */\n      let seen;\n      /** @type {Point | undefined} */\n      let point;\n\n      // Find the previous chunk (the one before the lazy line).\n      while (indexBeforeFlow--) {\n        if (self.events[indexBeforeFlow][0] === 'exit' && self.events[indexBeforeFlow][1].type === \"chunkFlow\") {\n          if (seen) {\n            point = self.events[indexBeforeFlow][1].end;\n            break;\n          }\n          seen = true;\n        }\n      }\n      exitContainers(continued);\n\n      // Fix positions.\n      index = indexBeforeExits;\n      while (index < self.events.length) {\n        self.events[index][1].end = {\n          ...point\n        };\n        index++;\n      }\n\n      // Inject the exits earlier (they‚Äôre still also at the end).\n      splice(self.events, indexBeforeFlow + 1, 0, self.events.slice(indexBeforeExits));\n\n      // Discard the duplicate exits.\n      self.events.length = index;\n    }\n  }\n\n  /**\n   * @param {number} size\n   *   Size.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function exitContainers(size) {\n    let index = stack.length;\n\n    // Exit open containers.\n    while (index-- > size) {\n      const entry = stack[index];\n      self.containerState = entry[1];\n      entry[0].exit.call(self, effects);\n    }\n    stack.length = size;\n  }\n  function closeFlow() {\n    childFlow.write([null]);\n    childToken = undefined;\n    childFlow = undefined;\n    self.containerState._closeFlow = undefined;\n  }\n}\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n *   Tokenizer.\n */\nfunction tokenizeContainer(effects, ok, nok) {\n  // Always populated by defaults.\n\n  return factorySpace(effects, effects.attempt(this.parser.constructs.document, ok, nok), \"linePrefix\", this.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4);\n}","/**\n * @import {\n *   InitialConstruct,\n *   Initializer,\n *   State,\n *   TokenizeContext\n * } from 'micromark-util-types'\n */\n\nimport { blankLine, content } from 'micromark-core-commonmark';\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\n/** @type {InitialConstruct} */\nexport const flow = {\n  tokenize: initializeFlow\n};\n\n/**\n * @this {TokenizeContext}\n *   Self.\n * @type {Initializer}\n *   Initializer.\n */\nfunction initializeFlow(effects) {\n  const self = this;\n  const initial = effects.attempt(\n  // Try to parse a blank line.\n  blankLine, atBlankEnding,\n  // Try to parse initial flow (essentially, only code).\n  effects.attempt(this.parser.constructs.flowInitial, afterConstruct, factorySpace(effects, effects.attempt(this.parser.constructs.flow, afterConstruct, effects.attempt(content, afterConstruct)), \"linePrefix\")));\n  return initial;\n\n  /** @type {State} */\n  function atBlankEnding(code) {\n    if (code === null) {\n      effects.consume(code);\n      return;\n    }\n    effects.enter(\"lineEndingBlank\");\n    effects.consume(code);\n    effects.exit(\"lineEndingBlank\");\n    self.currentConstruct = undefined;\n    return initial;\n  }\n\n  /** @type {State} */\n  function afterConstruct(code) {\n    if (code === null) {\n      effects.consume(code);\n      return;\n    }\n    effects.enter(\"lineEnding\");\n    effects.consume(code);\n    effects.exit(\"lineEnding\");\n    self.currentConstruct = undefined;\n    return initial;\n  }\n}","/**\n * @import {\n *   Code,\n *   InitialConstruct,\n *   Initializer,\n *   Resolver,\n *   State,\n *   TokenizeContext\n * } from 'micromark-util-types'\n */\n\nexport const resolver = {\n  resolveAll: createResolver()\n};\nexport const string = initializeFactory('string');\nexport const text = initializeFactory('text');\n\n/**\n * @param {'string' | 'text'} field\n *   Field.\n * @returns {InitialConstruct}\n *   Construct.\n */\nfunction initializeFactory(field) {\n  return {\n    resolveAll: createResolver(field === 'text' ? resolveAllLineSuffixes : undefined),\n    tokenize: initializeText\n  };\n\n  /**\n   * @this {TokenizeContext}\n   *   Context.\n   * @type {Initializer}\n   */\n  function initializeText(effects) {\n    const self = this;\n    const constructs = this.parser.constructs[field];\n    const text = effects.attempt(constructs, start, notText);\n    return start;\n\n    /** @type {State} */\n    function start(code) {\n      return atBreak(code) ? text(code) : notText(code);\n    }\n\n    /** @type {State} */\n    function notText(code) {\n      if (code === null) {\n        effects.consume(code);\n        return;\n      }\n      effects.enter(\"data\");\n      effects.consume(code);\n      return data;\n    }\n\n    /** @type {State} */\n    function data(code) {\n      if (atBreak(code)) {\n        effects.exit(\"data\");\n        return text(code);\n      }\n\n      // Data.\n      effects.consume(code);\n      return data;\n    }\n\n    /**\n     * @param {Code} code\n     *   Code.\n     * @returns {boolean}\n     *   Whether the code is a break.\n     */\n    function atBreak(code) {\n      if (code === null) {\n        return true;\n      }\n      const list = constructs[code];\n      let index = -1;\n      if (list) {\n        // Always populated by defaults.\n\n        while (++index < list.length) {\n          const item = list[index];\n          if (!item.previous || item.previous.call(self, self.previous)) {\n            return true;\n          }\n        }\n      }\n      return false;\n    }\n  }\n}\n\n/**\n * @param {Resolver | undefined} [extraResolver]\n *   Resolver.\n * @returns {Resolver}\n *   Resolver.\n */\nfunction createResolver(extraResolver) {\n  return resolveAllText;\n\n  /** @type {Resolver} */\n  function resolveAllText(events, context) {\n    let index = -1;\n    /** @type {number | undefined} */\n    let enter;\n\n    // A rather boring computation (to merge adjacent `data` events) which\n    // improves mm performance by 29%.\n    while (++index <= events.length) {\n      if (enter === undefined) {\n        if (events[index] && events[index][1].type === \"data\") {\n          enter = index;\n          index++;\n        }\n      } else if (!events[index] || events[index][1].type !== \"data\") {\n        // Don‚Äôt do anything if there is one data token.\n        if (index !== enter + 2) {\n          events[enter][1].end = events[index - 1][1].end;\n          events.splice(enter + 2, index - enter - 2);\n          index = enter + 2;\n        }\n        enter = undefined;\n      }\n    }\n    return extraResolver ? extraResolver(events, context) : events;\n  }\n}\n\n/**\n * A rather ugly set of instructions which again looks at chunks in the input\n * stream.\n * The reason to do this here is that it is *much* faster to parse in reverse.\n * And that we can‚Äôt hook into `null` to split the line suffix before an EOF.\n * To do: figure out if we can make this into a clean utility, or even in core.\n * As it will be useful for GFMs literal autolink extension (and maybe even\n * tables?)\n *\n * @type {Resolver}\n */\nfunction resolveAllLineSuffixes(events, context) {\n  let eventIndex = 0; // Skip first.\n\n  while (++eventIndex <= events.length) {\n    if ((eventIndex === events.length || events[eventIndex][1].type === \"lineEnding\") && events[eventIndex - 1][1].type === \"data\") {\n      const data = events[eventIndex - 1][1];\n      const chunks = context.sliceStream(data);\n      let index = chunks.length;\n      let bufferIndex = -1;\n      let size = 0;\n      /** @type {boolean | undefined} */\n      let tabs;\n      while (index--) {\n        const chunk = chunks[index];\n        if (typeof chunk === 'string') {\n          bufferIndex = chunk.length;\n          while (chunk.charCodeAt(bufferIndex - 1) === 32) {\n            size++;\n            bufferIndex--;\n          }\n          if (bufferIndex) break;\n          bufferIndex = -1;\n        }\n        // Number\n        else if (chunk === -2) {\n          tabs = true;\n          size++;\n        } else if (chunk === -1) {\n          // Empty\n        } else {\n          // Replacement character, exit.\n          index++;\n          break;\n        }\n      }\n\n      // Allow final trailing whitespace.\n      if (context._contentTypeTextTrailing && eventIndex === events.length) {\n        size = 0;\n      }\n      if (size) {\n        const token = {\n          type: eventIndex === events.length || tabs || size < 2 ? \"lineSuffix\" : \"hardBreakTrailing\",\n          start: {\n            _bufferIndex: index ? bufferIndex : data.start._bufferIndex + bufferIndex,\n            _index: data.start._index + index,\n            line: data.end.line,\n            column: data.end.column - size,\n            offset: data.end.offset - size\n          },\n          end: {\n            ...data.end\n          }\n        };\n        data.end = {\n          ...token.start\n        };\n        if (data.start.offset === data.end.offset) {\n          Object.assign(data, token);\n        } else {\n          events.splice(eventIndex, 0, ['enter', token, context], ['exit', token, context]);\n          eventIndex += 2;\n        }\n      }\n      eventIndex++;\n    }\n  }\n  return events;\n}","/**\n * @import {Extension} from 'micromark-util-types'\n */\n\nimport { attention, autolink, blockQuote, characterEscape, characterReference, codeFenced, codeIndented, codeText, definition, hardBreakEscape, headingAtx, htmlFlow, htmlText, labelEnd, labelStartImage, labelStartLink, lineEnding, list, setextUnderline, thematicBreak } from 'micromark-core-commonmark';\nimport { resolver as resolveText } from './initialize/text.js';\n\n/** @satisfies {Extension['document']} */\nexport const document = {\n  [42]: list,\n  [43]: list,\n  [45]: list,\n  [48]: list,\n  [49]: list,\n  [50]: list,\n  [51]: list,\n  [52]: list,\n  [53]: list,\n  [54]: list,\n  [55]: list,\n  [56]: list,\n  [57]: list,\n  [62]: blockQuote\n};\n\n/** @satisfies {Extension['contentInitial']} */\nexport const contentInitial = {\n  [91]: definition\n};\n\n/** @satisfies {Extension['flowInitial']} */\nexport const flowInitial = {\n  [-2]: codeIndented,\n  [-1]: codeIndented,\n  [32]: codeIndented\n};\n\n/** @satisfies {Extension['flow']} */\nexport const flow = {\n  [35]: headingAtx,\n  [42]: thematicBreak,\n  [45]: [setextUnderline, thematicBreak],\n  [60]: htmlFlow,\n  [61]: setextUnderline,\n  [95]: thematicBreak,\n  [96]: codeFenced,\n  [126]: codeFenced\n};\n\n/** @satisfies {Extension['string']} */\nexport const string = {\n  [38]: characterReference,\n  [92]: characterEscape\n};\n\n/** @satisfies {Extension['text']} */\nexport const text = {\n  [-5]: lineEnding,\n  [-4]: lineEnding,\n  [-3]: lineEnding,\n  [33]: labelStartImage,\n  [38]: characterReference,\n  [42]: attention,\n  [60]: [autolink, htmlText],\n  [91]: labelStartLink,\n  [92]: [hardBreakEscape, characterEscape],\n  [93]: labelEnd,\n  [95]: attention,\n  [96]: codeText\n};\n\n/** @satisfies {Extension['insideSpan']} */\nexport const insideSpan = {\n  null: [attention, resolveText]\n};\n\n/** @satisfies {Extension['attentionMarkers']} */\nexport const attentionMarkers = {\n  null: [42, 95]\n};\n\n/** @satisfies {Extension['disable']} */\nexport const disable = {\n  null: []\n};","/**\n * @import {\n *   Chunk,\n *   Code,\n *   ConstructRecord,\n *   Construct,\n *   Effects,\n *   InitialConstruct,\n *   ParseContext,\n *   Point,\n *   State,\n *   TokenizeContext,\n *   Token\n * } from 'micromark-util-types'\n */\n\n/**\n * @callback Restore\n *   Restore the state.\n * @returns {undefined}\n *   Nothing.\n *\n * @typedef Info\n *   Info.\n * @property {Restore} restore\n *   Restore.\n * @property {number} from\n *   From.\n *\n * @callback ReturnHandle\n *   Handle a successful run.\n * @param {Construct} construct\n *   Construct.\n * @param {Info} info\n *   Info.\n * @returns {undefined}\n *   Nothing.\n */\n\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { push, splice } from 'micromark-util-chunked';\nimport { resolveAll } from 'micromark-util-resolve-all';\n/**\n * Create a tokenizer.\n * Tokenizers deal with one type of data (e.g., containers, flow, text).\n * The parser is the object dealing with it all.\n * `initialize` works like other constructs, except that only its `tokenize`\n * function is used, in which case it doesn‚Äôt receive an `ok` or `nok`.\n * `from` can be given to set the point before the first character, although\n * when further lines are indented, they must be set with `defineSkip`.\n *\n * @param {ParseContext} parser\n *   Parser.\n * @param {InitialConstruct} initialize\n *   Construct.\n * @param {Omit<Point, '_bufferIndex' | '_index'> | undefined} [from]\n *   Point (optional).\n * @returns {TokenizeContext}\n *   Context.\n */\nexport function createTokenizer(parser, initialize, from) {\n  /** @type {Point} */\n  let point = {\n    _bufferIndex: -1,\n    _index: 0,\n    line: from && from.line || 1,\n    column: from && from.column || 1,\n    offset: from && from.offset || 0\n  };\n  /** @type {Record<string, number>} */\n  const columnStart = {};\n  /** @type {Array<Construct>} */\n  const resolveAllConstructs = [];\n  /** @type {Array<Chunk>} */\n  let chunks = [];\n  /** @type {Array<Token>} */\n  let stack = [];\n  /** @type {boolean | undefined} */\n  let consumed = true;\n\n  /**\n   * Tools used for tokenizing.\n   *\n   * @type {Effects}\n   */\n  const effects = {\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    consume,\n    enter,\n    exit,\n    interrupt: constructFactory(onsuccessfulcheck, {\n      interrupt: true\n    })\n  };\n\n  /**\n   * State and tools for resolving and serializing.\n   *\n   * @type {TokenizeContext}\n   */\n  const context = {\n    code: null,\n    containerState: {},\n    defineSkip,\n    events: [],\n    now,\n    parser,\n    previous: null,\n    sliceSerialize,\n    sliceStream,\n    write\n  };\n\n  /**\n   * The state function.\n   *\n   * @type {State | undefined}\n   */\n  let state = initialize.tokenize.call(context, effects);\n\n  /**\n   * Track which character we expect to be consumed, to catch bugs.\n   *\n   * @type {Code}\n   */\n  let expectedCode;\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize);\n  }\n  return context;\n\n  /** @type {TokenizeContext['write']} */\n  function write(slice) {\n    chunks = push(chunks, slice);\n    main();\n\n    // Exit if we‚Äôre not done, resolve might change stuff.\n    if (chunks[chunks.length - 1] !== null) {\n      return [];\n    }\n    addResult(initialize, 0);\n\n    // Otherwise, resolve, and exit.\n    context.events = resolveAll(resolveAllConstructs, context.events, context);\n    return context.events;\n  }\n\n  //\n  // Tools.\n  //\n\n  /** @type {TokenizeContext['sliceSerialize']} */\n  function sliceSerialize(token, expandTabs) {\n    return serializeChunks(sliceStream(token), expandTabs);\n  }\n\n  /** @type {TokenizeContext['sliceStream']} */\n  function sliceStream(token) {\n    return sliceChunks(chunks, token);\n  }\n\n  /** @type {TokenizeContext['now']} */\n  function now() {\n    // This is a hot path, so we clone manually instead of `Object.assign({}, point)`\n    const {\n      _bufferIndex,\n      _index,\n      line,\n      column,\n      offset\n    } = point;\n    return {\n      _bufferIndex,\n      _index,\n      line,\n      column,\n      offset\n    };\n  }\n\n  /** @type {TokenizeContext['defineSkip']} */\n  function defineSkip(value) {\n    columnStart[value.line] = value.column;\n    accountForPotentialSkip();\n  }\n\n  //\n  // State management.\n  //\n\n  /**\n   * Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n   * `consume`).\n   * Here is where we walk through the chunks, which either include strings of\n   * several characters, or numerical character codes.\n   * The reason to do this in a loop instead of a call is so the stack can\n   * drain.\n   *\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function main() {\n    /** @type {number} */\n    let chunkIndex;\n    while (point._index < chunks.length) {\n      const chunk = chunks[point._index];\n\n      // If we‚Äôre in a buffer chunk, loop through it.\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index;\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0;\n        }\n        while (point._index === chunkIndex && point._bufferIndex < chunk.length) {\n          go(chunk.charCodeAt(point._bufferIndex));\n        }\n      } else {\n        go(chunk);\n      }\n    }\n  }\n\n  /**\n   * Deal with one code.\n   *\n   * @param {Code} code\n   *   Code.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function go(code) {\n    consumed = undefined;\n    expectedCode = code;\n    state = state(code);\n  }\n\n  /** @type {Effects['consume']} */\n  function consume(code) {\n    if (markdownLineEnding(code)) {\n      point.line++;\n      point.column = 1;\n      point.offset += code === -3 ? 2 : 1;\n      accountForPotentialSkip();\n    } else if (code !== -1) {\n      point.column++;\n      point.offset++;\n    }\n\n    // Not in a string chunk.\n    if (point._bufferIndex < 0) {\n      point._index++;\n    } else {\n      point._bufferIndex++;\n\n      // At end of string chunk.\n      if (point._bufferIndex ===\n      // Points w/ non-negative `_bufferIndex` reference\n      // strings.\n      /** @type {string} */\n      chunks[point._index].length) {\n        point._bufferIndex = -1;\n        point._index++;\n      }\n    }\n\n    // Expose the previous character.\n    context.previous = code;\n\n    // Mark as consumed.\n    consumed = true;\n  }\n\n  /** @type {Effects['enter']} */\n  function enter(type, fields) {\n    /** @type {Token} */\n    // @ts-expect-error Patch instead of assign required fields to help GC.\n    const token = fields || {};\n    token.type = type;\n    token.start = now();\n    context.events.push(['enter', token, context]);\n    stack.push(token);\n    return token;\n  }\n\n  /** @type {Effects['exit']} */\n  function exit(type) {\n    const token = stack.pop();\n    token.end = now();\n    context.events.push(['exit', token, context]);\n    return token;\n  }\n\n  /**\n   * Use results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from);\n  }\n\n  /**\n   * Discard results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulcheck(_, info) {\n    info.restore();\n  }\n\n  /**\n   * Factory to attempt/check/interrupt.\n   *\n   * @param {ReturnHandle} onreturn\n   *   Callback.\n   * @param {{interrupt?: boolean | undefined} | undefined} [fields]\n   *   Fields.\n   */\n  function constructFactory(onreturn, fields) {\n    return hook;\n\n    /**\n     * Handle either an object mapping codes to constructs, a list of\n     * constructs, or a single construct.\n     *\n     * @param {Array<Construct> | ConstructRecord | Construct} constructs\n     *   Constructs.\n     * @param {State} returnState\n     *   State.\n     * @param {State | undefined} [bogusState]\n     *   State.\n     * @returns {State}\n     *   State.\n     */\n    function hook(constructs, returnState, bogusState) {\n      /** @type {ReadonlyArray<Construct>} */\n      let listOfConstructs;\n      /** @type {number} */\n      let constructIndex;\n      /** @type {Construct} */\n      let currentConstruct;\n      /** @type {Info} */\n      let info;\n      return Array.isArray(constructs) ? /* c8 ignore next 1 */\n      handleListOfConstructs(constructs) : 'tokenize' in constructs ?\n      // Looks like a construct.\n      handleListOfConstructs([(/** @type {Construct} */constructs)]) : handleMapOfConstructs(constructs);\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ConstructRecord} map\n       *   Constructs.\n       * @returns {State}\n       *   State.\n       */\n      function handleMapOfConstructs(map) {\n        return start;\n\n        /** @type {State} */\n        function start(code) {\n          const left = code !== null && map[code];\n          const all = code !== null && map.null;\n          const list = [\n          // To do: add more extension tests.\n          /* c8 ignore next 2 */\n          ...(Array.isArray(left) ? left : left ? [left] : []), ...(Array.isArray(all) ? all : all ? [all] : [])];\n          return handleListOfConstructs(list)(code);\n        }\n      }\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ReadonlyArray<Construct>} list\n       *   Constructs.\n       * @returns {State}\n       *   State.\n       */\n      function handleListOfConstructs(list) {\n        listOfConstructs = list;\n        constructIndex = 0;\n        if (list.length === 0) {\n          return bogusState;\n        }\n        return handleConstruct(list[constructIndex]);\n      }\n\n      /**\n       * Handle a single construct.\n       *\n       * @param {Construct} construct\n       *   Construct.\n       * @returns {State}\n       *   State.\n       */\n      function handleConstruct(construct) {\n        return start;\n\n        /** @type {State} */\n        function start(code) {\n          // To do: not needed to store if there is no bogus state, probably?\n          // Currently doesn‚Äôt work because `inspect` in document does a check\n          // w/o a bogus, which doesn‚Äôt make sense. But it does seem to help perf\n          // by not storing.\n          info = store();\n          currentConstruct = construct;\n          if (!construct.partial) {\n            context.currentConstruct = construct;\n          }\n\n          // Always populated by defaults.\n\n          if (construct.name && context.parser.constructs.disable.null.includes(construct.name)) {\n            return nok(code);\n          }\n          return construct.tokenize.call(\n          // If we do have fields, create an object w/ `context` as its\n          // prototype.\n          // This allows a ‚Äúlive binding‚Äù, which is needed for `interrupt`.\n          fields ? Object.assign(Object.create(context), fields) : context, effects, ok, nok)(code);\n        }\n      }\n\n      /** @type {State} */\n      function ok(code) {\n        consumed = true;\n        onreturn(currentConstruct, info);\n        return returnState;\n      }\n\n      /** @type {State} */\n      function nok(code) {\n        consumed = true;\n        info.restore();\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex]);\n        }\n        return bogusState;\n      }\n    }\n  }\n\n  /**\n   * @param {Construct} construct\n   *   Construct.\n   * @param {number} from\n   *   From.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function addResult(construct, from) {\n    if (construct.resolveAll && !resolveAllConstructs.includes(construct)) {\n      resolveAllConstructs.push(construct);\n    }\n    if (construct.resolve) {\n      splice(context.events, from, context.events.length - from, construct.resolve(context.events.slice(from), context));\n    }\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context);\n    }\n  }\n\n  /**\n   * Store state.\n   *\n   * @returns {Info}\n   *   Info.\n   */\n  function store() {\n    const startPoint = now();\n    const startPrevious = context.previous;\n    const startCurrentConstruct = context.currentConstruct;\n    const startEventsIndex = context.events.length;\n    const startStack = Array.from(stack);\n    return {\n      from: startEventsIndex,\n      restore\n    };\n\n    /**\n     * Restore state.\n     *\n     * @returns {undefined}\n     *   Nothing.\n     */\n    function restore() {\n      point = startPoint;\n      context.previous = startPrevious;\n      context.currentConstruct = startCurrentConstruct;\n      context.events.length = startEventsIndex;\n      stack = startStack;\n      accountForPotentialSkip();\n    }\n  }\n\n  /**\n   * Move the current point a bit forward in the line when it‚Äôs on a column\n   * skip.\n   *\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line];\n      point.offset += columnStart[point.line] - 1;\n    }\n  }\n}\n\n/**\n * Get the chunks from a slice of chunks in the range of a token.\n *\n * @param {ReadonlyArray<Chunk>} chunks\n *   Chunks.\n * @param {Pick<Token, 'end' | 'start'>} token\n *   Token.\n * @returns {Array<Chunk>}\n *   Chunks.\n */\nfunction sliceChunks(chunks, token) {\n  const startIndex = token.start._index;\n  const startBufferIndex = token.start._bufferIndex;\n  const endIndex = token.end._index;\n  const endBufferIndex = token.end._bufferIndex;\n  /** @type {Array<Chunk>} */\n  let view;\n  if (startIndex === endIndex) {\n    // @ts-expect-error `_bufferIndex` is used on string chunks.\n    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)];\n  } else {\n    view = chunks.slice(startIndex, endIndex);\n    if (startBufferIndex > -1) {\n      const head = view[0];\n      if (typeof head === 'string') {\n        view[0] = head.slice(startBufferIndex);\n        /* c8 ignore next 4 -- used to be used, no longer */\n      } else {\n        view.shift();\n      }\n    }\n    if (endBufferIndex > 0) {\n      // @ts-expect-error `_bufferIndex` is used on string chunks.\n      view.push(chunks[endIndex].slice(0, endBufferIndex));\n    }\n  }\n  return view;\n}\n\n/**\n * Get the string value of a slice of chunks.\n *\n * @param {ReadonlyArray<Chunk>} chunks\n *   Chunks.\n * @param {boolean | undefined} [expandTabs=false]\n *   Whether to expand tabs (default: `false`).\n * @returns {string}\n *   Result.\n */\nfunction serializeChunks(chunks, expandTabs) {\n  let index = -1;\n  /** @type {Array<string>} */\n  const result = [];\n  /** @type {boolean | undefined} */\n  let atTab;\n  while (++index < chunks.length) {\n    const chunk = chunks[index];\n    /** @type {string} */\n    let value;\n    if (typeof chunk === 'string') {\n      value = chunk;\n    } else switch (chunk) {\n      case -5:\n        {\n          value = \"\\r\";\n          break;\n        }\n      case -4:\n        {\n          value = \"\\n\";\n          break;\n        }\n      case -3:\n        {\n          value = \"\\r\" + \"\\n\";\n          break;\n        }\n      case -2:\n        {\n          value = expandTabs ? \" \" : \"\\t\";\n          break;\n        }\n      case -1:\n        {\n          if (!expandTabs && atTab) continue;\n          value = \" \";\n          break;\n        }\n      default:\n        {\n          // Currently only replacement character.\n          value = String.fromCharCode(chunk);\n        }\n    }\n    atTab = chunk === -2;\n    result.push(value);\n  }\n  return result.join('');\n}","/**\n * @import {\n *   Create,\n *   FullNormalizedExtension,\n *   InitialConstruct,\n *   ParseContext,\n *   ParseOptions\n * } from 'micromark-util-types'\n */\n\nimport { combineExtensions } from 'micromark-util-combine-extensions';\nimport { content } from './initialize/content.js';\nimport { document } from './initialize/document.js';\nimport { flow } from './initialize/flow.js';\nimport { string, text } from './initialize/text.js';\nimport * as defaultConstructs from './constructs.js';\nimport { createTokenizer } from './create-tokenizer.js';\n\n/**\n * @param {ParseOptions | null | undefined} [options]\n *   Configuration (optional).\n * @returns {ParseContext}\n *   Parser.\n */\nexport function parse(options) {\n  const settings = options || {};\n  const constructs = /** @type {FullNormalizedExtension} */\n  combineExtensions([defaultConstructs, ...(settings.extensions || [])]);\n\n  /** @type {ParseContext} */\n  const parser = {\n    constructs,\n    content: create(content),\n    defined: [],\n    document: create(document),\n    flow: create(flow),\n    lazy: {},\n    string: create(string),\n    text: create(text)\n  };\n  return parser;\n\n  /**\n   * @param {InitialConstruct} initial\n   *   Construct to start with.\n   * @returns {Create}\n   *   Create a tokenizer.\n   */\n  function create(initial) {\n    return creator;\n    /** @type {Create} */\n    function creator(from) {\n      return createTokenizer(parser, initial, from);\n    }\n  }\n}","/**\n * @import {Event} from 'micromark-util-types'\n */\n\nimport { subtokenize } from 'micromark-util-subtokenize';\n\n/**\n * @param {Array<Event>} events\n *   Events.\n * @returns {Array<Event>}\n *   Events.\n */\nexport function postprocess(events) {\n  while (!subtokenize(events)) {\n    // Empty\n  }\n  return events;\n}","/**\n * @import {Chunk, Code, Encoding, Value} from 'micromark-util-types'\n */\n\n/**\n * @callback Preprocessor\n *   Preprocess a value.\n * @param {Value} value\n *   Value.\n * @param {Encoding | null | undefined} [encoding]\n *   Encoding when `value` is a typed array (optional).\n * @param {boolean | null | undefined} [end=false]\n *   Whether this is the last chunk (default: `false`).\n * @returns {Array<Chunk>}\n *   Chunks.\n */\n\nconst search = /[\\0\\t\\n\\r]/g;\n\n/**\n * @returns {Preprocessor}\n *   Preprocess a value.\n */\nexport function preprocess() {\n  let column = 1;\n  let buffer = '';\n  /** @type {boolean | undefined} */\n  let start = true;\n  /** @type {boolean | undefined} */\n  let atCarriageReturn;\n  return preprocessor;\n\n  /** @type {Preprocessor} */\n  // eslint-disable-next-line complexity\n  function preprocessor(value, encoding, end) {\n    /** @type {Array<Chunk>} */\n    const chunks = [];\n    /** @type {RegExpMatchArray | null} */\n    let match;\n    /** @type {number} */\n    let next;\n    /** @type {number} */\n    let startPosition;\n    /** @type {number} */\n    let endPosition;\n    /** @type {Code} */\n    let code;\n    value = buffer + (typeof value === 'string' ? value.toString() : new TextDecoder(encoding || undefined).decode(value));\n    startPosition = 0;\n    buffer = '';\n    if (start) {\n      // To do: `markdown-rs` actually parses BOMs (byte order mark).\n      if (value.charCodeAt(0) === 65279) {\n        startPosition++;\n      }\n      start = undefined;\n    }\n    while (startPosition < value.length) {\n      search.lastIndex = startPosition;\n      match = search.exec(value);\n      endPosition = match && match.index !== undefined ? match.index : value.length;\n      code = value.charCodeAt(endPosition);\n      if (!match) {\n        buffer = value.slice(startPosition);\n        break;\n      }\n      if (code === 10 && startPosition === endPosition && atCarriageReturn) {\n        chunks.push(-3);\n        atCarriageReturn = undefined;\n      } else {\n        if (atCarriageReturn) {\n          chunks.push(-5);\n          atCarriageReturn = undefined;\n        }\n        if (startPosition < endPosition) {\n          chunks.push(value.slice(startPosition, endPosition));\n          column += endPosition - startPosition;\n        }\n        switch (code) {\n          case 0:\n            {\n              chunks.push(65533);\n              column++;\n              break;\n            }\n          case 9:\n            {\n              next = Math.ceil(column / 4) * 4;\n              chunks.push(-2);\n              while (column++ < next) chunks.push(-1);\n              break;\n            }\n          case 10:\n            {\n              chunks.push(-4);\n              column = 1;\n              break;\n            }\n          default:\n            {\n              atCarriageReturn = true;\n              column = 1;\n            }\n        }\n      }\n      startPosition = endPosition + 1;\n    }\n    if (end) {\n      if (atCarriageReturn) chunks.push(-5);\n      if (buffer) chunks.push(buffer);\n      chunks.push(null);\n    }\n    return chunks;\n  }\n}","/**\n * @import {Encoding, Value} from 'micromark-util-types'\n */\n\n/**\n * @typedef {import('micromark-util-types').Options} Options\n */\n\nimport { compile } from './lib/compile.js';\nimport { parse } from './lib/parse.js';\nimport { postprocess } from './lib/postprocess.js';\nimport { preprocess } from './lib/preprocess.js';\nexport { compile } from './lib/compile.js';\nexport { parse } from './lib/parse.js';\nexport { postprocess } from './lib/postprocess.js';\nexport { preprocess } from './lib/preprocess.js';\n\n/**\n * Compile markdown to HTML.\n *\n * > Note: which encodings are supported depends on the engine.\n * > For info on Node.js, see:\n * > <https://nodejs.org/api/util.html#whatwg-supported-encodings>.\n *\n * @overload\n * @param {Value} value\n *   Markdown to parse (`string` or `Uint8Array`).\n * @param {Encoding | null | undefined} encoding\n *   Character encoding to understand `value` as when it‚Äôs a `Uint8Array`\n *   (`string`, default: `'utf8'`).\n * @param {Options | null | undefined} [options]\n *   Configuration.\n * @returns {string}\n *   Compiled HTML.\n *\n * @overload\n * @param {Value} value\n *   Markdown to parse (`string` or `Uint8Array`).\n * @param {Options | null | undefined} [options]\n *   Configuration.\n * @returns {string}\n *   Compiled HTML.\n *\n * @param {Value} value\n *   Markdown to parse (`string` or `Uint8Array`).\n * @param {Encoding | Options | null | undefined} [encoding]\n *   Character encoding to understand `value` as when it‚Äôs a `Uint8Array`\n *   (`string`, default: `'utf8'`).\n * @param {Options | null | undefined} [options]\n *   Configuration.\n * @returns {string}\n *   Compiled HTML.\n */\nexport function micromark(value, encoding, options) {\n  if (typeof encoding !== 'string') {\n    options = encoding;\n    encoding = undefined;\n  }\n  return compile(options)(postprocess(parse(options).document().write(preprocess()(value, encoding, true))));\n}"],"names":[],"sourceRoot":"","ignoreList":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]}